<!DOCTYPE html><html lang="en-US" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="generator" content="Jekyll v4.2.2" /><meta property="og:title" content="Understanding Kubernetes’ Cluster Networking" /><meta name="author" content="George Aristy" /><meta property="og:locale" content="en_US" /><meta name="description" content="Kubernetes is a system for automating deployment, scaling, and management of containerized applications. Networking is a central part of Kubernetes, and in this article we will explore how Kubernetes configures the cluster to handle east-west traffic. We’ll reserve discussion on north-south traffic for a later article." /><meta property="og:description" content="Kubernetes is a system for automating deployment, scaling, and management of containerized applications. Networking is a central part of Kubernetes, and in this article we will explore how Kubernetes configures the cluster to handle east-west traffic. We’ll reserve discussion on north-south traffic for a later article." /><link rel="canonical" href="https://georgearisty.dev/posts/k8s-cluster-network/" /><meta property="og:url" content="https://georgearisty.dev/posts/k8s-cluster-network/" /><meta property="og:site_name" content="George Aristy" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2023-03-10T08:50:00-05:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Understanding Kubernetes’ Cluster Networking" /><meta name="twitter:site" content="@twitter_username" /><meta name="twitter:creator" content="@George Aristy" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"George Aristy"},"dateModified":"2023-03-10T08:50:00-05:00","datePublished":"2023-03-10T08:50:00-05:00","description":"Kubernetes is a system for automating deployment, scaling, and management of containerized applications. Networking is a central part of Kubernetes, and in this article we will explore how Kubernetes configures the cluster to handle east-west traffic. We’ll reserve discussion on north-south traffic for a later article.","headline":"Understanding Kubernetes’ Cluster Networking","mainEntityOfPage":{"@type":"WebPage","@id":"https://georgearisty.dev/posts/k8s-cluster-network/"},"url":"https://georgearisty.dev/posts/k8s-cluster-network/"}</script><title>Understanding Kubernetes' Cluster Networking | George Aristy</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="George Aristy"><meta name="application-name" content="George Aristy"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="stylesheet" href="/assets/lib/fonts/main.css"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="stylesheet" href="/assets/lib/bootstrap-4.6.1/bootstrap.min.css"><link rel="stylesheet" href="/assets/lib/fontawesome-free-5.15.4/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="/assets/lib/bootstrap-toc-1.0.1/bootstrap-toc.min.css"><link rel="stylesheet" href="/assets/lib/magnific-popup-1.1.0/magnific-popup.css"> <script src="/assets/lib/jquery-3.6.0/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get MODE_ATTR() { return "data-mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener("change", () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_ATTR); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } } /* ModeToggle */ const toggle = new ModeToggle(); function flipMode() { if (toggle.hasMode) { if (toggle.isSysDarkPrefer) { if (toggle.isLightMode) { toggle.clearMode(); } else { toggle.setLight(); } } else { if (toggle.isDarkMode) { toggle.clearMode(); } else { toggle.setDark(); } } } else { if (toggle.isSysDarkPrefer) { toggle.setLight(); } else { toggle.setDark(); } } toggle.notify(); } /* flipMode() */ </script><body data-spy="scroll" data-target="#toc" data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src=" /assets/img/portrait.png " alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">George Aristy</a></div><div class="site-subtitle font-italic">Blog about software craftmanship</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a><li class="nav-item"> <a href="/bookshelf/" class="nav-link"> <i class="fa-fw fas fa-book ml-xl-3 mr-xl-3 unloaded"></i> <span>BOOKSHELF</span> </a><li class="nav-item"> <a href="/projects/" class="nav-link"> <i class="fa-fw fas fa-project-diagram ml-xl-3 mr-xl-3 unloaded"></i> <span>PROJECTS</span> </a><li class="nav-item"> <a href="/talks/" class="nav-link"> <i class="fa-fw fas fa-comment ml-xl-3 mr-xl-3 unloaded"></i> <span>TALKS</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/llorllale" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['george.aristy','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a> <a href="https://www.linkedin.com/in/georgearisty/" aria-label="linkedin" target="_blank" rel="noopener"> <i class="fab fa-linkedin"></i> </a> <a href="https://stackoverflow.com/users/1623885/george-aristy" aria-label="stack-overflow" target="_blank" rel="noopener"> <i class="fab fa-stack-overflow"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>Understanding Kubernetes' Cluster Networking</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>Understanding Kubernetes' Cluster Networking</h1><div class="post-meta text-muted"><div> By <em> <a href="https://www.linkedin.com/in/georgearisty">George Aristy</a> </em></div><div class="d-flex"><div> <span> Posted <em class="timeago" data-ts="1678456200" data-toggle="tooltip" data-placement="bottom" data-tooltip-df="llll" > 2023-03-10 </em> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="6618 words"> <em>36 min</em> read</span></div></div></div><div class="post-content"><p><img data-src="/assets/img/Kubernetes-icon-color.svg" alt="cover" class="left" width="100" data-proofer-ignore> <a href="https://kubernetes.io/">Kubernetes</a> is a system for automating deployment, scaling, and management of containerized applications. <a href="https://kubernetes.io/docs/concepts/cluster-administration/networking/">Networking is a central part of Kubernetes</a>, and in this article we will explore how Kubernetes configures the cluster to handle <a href="https://kubernetes.io/docs/concepts/cluster-administration/networking/">east-west traffic</a>. We’ll reserve discussion on north-south traffic for a later article.</p><p><br /></p><blockquote class="prompt-warning"><div><p>This article is long and a bit heavy-handed on annotations, command-line instructions, and pointers to implementations in Kubernetes and associated components. There are dozens of footnotes. We are diving into fairly deep waters here. I tried my best to keep a coherent flow going. Feel free to drop a comment below if you notice a mistake somewhere or if you’d like to offer editorial advice.</p></div></blockquote><h1 id="concepts">Concepts</h1><p>By default, all pods in a K8s cluster can communicate with each other without <a href="https://en.wikipedia.org/wiki/Network_address_translation">NAT</a> (<a href="https://kubernetes.io/docs/concepts/services-networking/">source</a>)<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup>, therefore each pod is assigned a cluster-wide IP address. Containers within each pod share the pod’s network namespace, allowing them to communicate with each other on <code class="language-plaintext highlighter-rouge">localhost</code> via the <code class="language-plaintext highlighter-rouge">loopback</code> interface. From the point of view of the workloads running inside the containers, this IP network looks like any other and no changes are necessary.</p><p><img data-src="/assets/img/k8s-networking/k8s-pod-container-network.svg" alt="k8s-pod-container-network" data-proofer-ignore> <em>Conceptual view of inter-Pod and intra-Pod network communication.</em></p><p>Recall from a previous article that as far as K8s components go, the <a href="/posts/kubernetes-in-action/#node-components">kubelet and the kube-proxy</a> are responsible for creating pods and applying network configurations on the cluster’s nodes.</p><p>When the pod is being created or terminated, part of the <code class="language-plaintext highlighter-rouge">kubelet</code>’s job is to set up or cleanup the pod’s sandbox on the node it is running on. The <code class="language-plaintext highlighter-rouge">kubelet</code> relies on the <a href="https://github.com/kubernetes/cri-api">Container Runtime Interface</a> (CRI) implementation to handle the details of creating and destroying sandboxes. The CRI is composed of several interfaces; the interesting ones for us are the <a href="https://github.com/kubernetes/cri-api/blob/adbbc6d75b383d6b823c24bba946029458d6681b/pkg/apis/services.go#L106-L118"><code class="language-plaintext highlighter-rouge">RuntimeService</code></a> interface (client-side API; integration point <code class="language-plaintext highlighter-rouge">kubelet</code>-&gt;CRI) and the <a href="https://github.com/kubernetes/cri-api/blob/adbbc6d75b383d6b823c24bba946029458d6681b/pkg/apis/runtime/v1/api.pb.go#L10453-L10543"><code class="language-plaintext highlighter-rouge">RuntimeServiceServer</code></a> interface (server-side API; integration point <code class="language-plaintext highlighter-rouge">RuntimeService</code>-&gt;CRI implementation). These APIs are both big and fat, but for this article we are only interested in the <code class="language-plaintext highlighter-rouge">*PodSandbox</code> set of methods (e.g. <code class="language-plaintext highlighter-rouge">RunPodSandbox</code>). Underneath the CRI’s hood, however, is the <a href="https://github.com/containernetworking/cni">Container Network Interface</a> that creates and configures the pod’s <a href="https://en.wikipedia.org/wiki/Linux_namespaces#Network_(net)">network namespace</a><sup id="fnref:11" role="doc-noteref"><a href="#fn:11" class="footnote" rel="footnote">2</a></sup>.</p><p>The <code class="language-plaintext highlighter-rouge">kube-proxy</code> configures routing rules to proxy traffic directed at <a href="https://kubernetes.io/docs/concepts/services-networking/service/"><code class="language-plaintext highlighter-rouge">Services</code></a> and performs simple load-balancing between the corresponding <a href="https://kubernetes.io/docs/concepts/services-networking/service/#endpoints"><code class="language-plaintext highlighter-rouge">Endpoints</code></a><sup id="fnref:6" role="doc-noteref"><a href="#fn:6" class="footnote" rel="footnote">3</a></sup>.</p><p>Finally, a third component, <a href="https://github.com/coredns/coredns"><code class="language-plaintext highlighter-rouge">coreDNS</code></a>, resolves network names by looking them up in <code class="language-plaintext highlighter-rouge">etcd</code>.</p><p><img data-src="/assets/img/k8s-networking/k8s-cri-network.svg" alt="k8s-pod-sandbox-network" data-proofer-ignore> <em>Components involved in the network configuration for a pod. Blue circles are pods and orange rectangles are daemons. Note that <code class="language-plaintext highlighter-rouge">etcd</code> is shown here as a database service, but it is also deployed as a pod.</em></p><p>In the next section we will understand how pod networking works by manually creating our own pods and have a client in one pod invoke an API in a different pod.</p><blockquote class="prompt-info"><div><p>I will be using a simple K8s cluster I set up with <a href="https://github.com/kubernetes-sigs/kind"><code class="language-plaintext highlighter-rouge">kind</code></a> in the walkthrough below. <code class="language-plaintext highlighter-rouge">kind</code> creates a docker container per K8s node. You may choose a similar sandbox, machine instances in the cloud, or any other setup that simulates at least two host machines connected to the same network. Also note that Linux hosts are used for this walkthrough.</p></div></blockquote><h1 id="create-your-own-pod-network">Create your own Pod Network</h1><p>We will manually create pods on different hosts to gain an understanding of how Kubernetes’ networking is configured under the hood.</p><h2 id="network-namespaces"><span class="mr-2">Network namespaces</span><a href="#network-namespaces" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><p>Linux has a concept called <a href="https://en.wikipedia.org/wiki/Linux_namespaces">namespaces</a>. Namespaces are a feature that isolate the resources that a process sees from another processes. For example, a process may see MySQL running with PID 123 but a different process running in a different namespace (but on the same host) will see a different process assigned to PID 123, or none at all.</p><p>There are different kinds of namespaces; we are interested in the <a href="https://en.wikipedia.org/wiki/Linux_namespaces#Network_(net)">Network (net)</a> namespace.</p><p>Each namespace has a virtual <code class="language-plaintext highlighter-rouge">loopback</code> interface and <em>may</em> have additional virtual network devices attached. Each of these virtual devices may be assigned exclusive or overlapping IP address ranges.</p><h3 id="localhost"><span class="mr-2">localhost</span><a href="#localhost" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><p>Processes running inside the same <code class="language-plaintext highlighter-rouge">net</code> namespace can send messages to each other over <code class="language-plaintext highlighter-rouge">localhost</code>.</p><blockquote class="prompt-tip"><div><p><strong>Hands On</strong></p><p>Create a <code class="language-plaintext highlighter-rouge">net</code> namespace with a client and a server:</p><details> <summary>On a host we’ll call “client”</summary><div><div class="language-shell highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
</pre><td class="rouge-code"><pre><span class="c"># create network namespace</span>
root@kind-control-plane:/# ip netns add client
root@kind-control-plane:/# ip netns list
client

<span class="c"># `loopback` is DOWN by default</span>
root@kind-control-plane:/# ip netns <span class="nb">exec </span>client ip <span class="nb">link </span>list
1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noqueue state DOWN mode DEFAULT group default qlen 1000
   <span class="nb">link</span>/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00

<span class="c"># initialize `loopback` (`lo` is shorthand for "loopback")</span>
root@kind-control-plane:/# ip netns <span class="nb">exec </span>client ip <span class="nb">link set </span>lo up

<span class="c"># start the server</span>
root@kind-control-plane:/# ip netns <span class="nb">exec </span>client <span class="nb">nohup </span>python3 <span class="nt">-m</span> http.server 8080 &amp;
<span class="o">[</span>1] 29509
root@kind-control-plane:/# <span class="nb">nohup</span>: ignoring input and appending output to <span class="s1">'nohup.out'</span>

<span class="c"># invoke the server</span>
root@kind-control-plane:/# ip netns <span class="nb">exec </span>client curl <span class="nt">-m</span> 2 localhost:8080
&lt;<span class="o">!</span>DOCTYPE HTML PUBLIC <span class="s2">"-//W3C//DTD HTML 4.01//EN"</span> <span class="s2">"http://www.w3.org/TR/html4/strict.dtd"</span><span class="o">&gt;</span>
&lt;html&gt;
&lt;<span class="nb">head</span><span class="o">&gt;</span>
&lt;meta http-equiv<span class="o">=</span><span class="s2">"Content-Type"</span> <span class="nv">content</span><span class="o">=</span><span class="s2">"text/html; charset=utf-8"</span><span class="o">&gt;</span>
&lt;title&gt;Directory listing <span class="k">for</span> /&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;h1&gt;Directory listing <span class="k">for</span> /&lt;/h1&gt;
&lt;hr&gt;
&lt;ul&gt;
...
&lt;/ul&gt;
&lt;hr&gt;
&lt;/body&gt;
&lt;/html&gt;
</pre></table></code></div></div></div></details></div></blockquote><p><img data-src="/assets/img/k8s-networking/pod-sandbox.svg" alt="pod-sandbox" data-proofer-ignore> <em>Traffic from a client to a server inside a network namespace. <font color="blue"><strong>Blue</strong></font> is traffic on <code class="language-plaintext highlighter-rouge">localhost</code>. Notice the host’s interface (<code class="language-plaintext highlighter-rouge">eth0</code>) is bypassed entirely for this traffic.</em></p><p>With this we have one or more processes that can communicate over <code class="language-plaintext highlighter-rouge">localhost</code>. This is exactly how K8s Pods work, and these “processes” are K8s containers.</p><h2 id="connecting-network-namespaces-on-the-same-host"><span class="mr-2">Connecting network namespaces on the same host</span><a href="#connecting-network-namespaces-on-the-same-host" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><p>Remember that all pods in a K8s cluster can communicate with each other without NAT. So, how would two pods on the same host communicate with each other? Let’s give it a shot. Let’s create a “server” namespace and attempt to communicate with it.</p><blockquote class="prompt-tip"><div><p><strong>Hands On</strong></p><details> <summary>On the same “client” host</summary><div><div class="language-shell highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre><td class="rouge-code"><pre><span class="c"># create the other pod's network namespace</span>
root@kind-control-plane:/# ip netns add server
root@kind-control-plane:/# ip netns list
server
client

<span class="c"># stop the server you had running before and restart it in the new `server` namespace</span>
root@kind-control-plane:/# ip netns <span class="nb">exec </span>server <span class="nb">nohup </span>python3 <span class="nt">-m</span> http.server 8080 &amp;
<span class="o">[</span>1] 29538
root@kind-control-plane:/# <span class="nb">nohup</span>: ignoring input and appending output to <span class="s1">'nohup.out'</span>

<span class="c"># attempt to call this server from the client namespace</span>
root@kind-control-plane:/# ip netns <span class="nb">exec </span>client curl localhost:8080 
curl: <span class="o">(</span>7<span class="o">)</span> Failed to connect to localhost port 8080 after 0 ms: Connection refused
</pre></table></code></div></div></div></details></div></blockquote><p><img data-src="/assets/img/k8s-networking/disconnected-pods.svg" alt="disconnected-pods" data-proofer-ignore></p><p>We don’t have an address for <code class="language-plaintext highlighter-rouge">server</code> from within the <code class="language-plaintext highlighter-rouge">client</code> namespace yet. These two network namespaces are completely disconnected from each other. All <code class="language-plaintext highlighter-rouge">client</code> and <code class="language-plaintext highlighter-rouge">server</code> have is <code class="language-plaintext highlighter-rouge">localhost</code> (dev <code class="language-plaintext highlighter-rouge">lo</code>) which is always assigned <code class="language-plaintext highlighter-rouge">127.0.0.1</code>. We need another interface between these two namespaces for communication to happen.</p><p>Linux has the concept of <em>Virtual Ethernet Devices</em> (<a href="https://man7.org/linux/man-pages/man4/veth.4.html">veth</a>) that act like “pipes” through which network packets flow, and of which you can attach either end to a namespace or a device. The “ends” of these “pipes” act as virtual devices to which IP addresses can be assigned. It is perfectly possible to create a <em>veth</em> device and connect our two namespaces like this:</p><p><img data-src="/assets/img/k8s-networking/pods-veth.svg" alt="pods-veth" data-proofer-ignore></p><p>However, consider that <code class="language-plaintext highlighter-rouge">veth</code> are <em>point-to-point</em> devices with just two ends and, remembering our requirement that all Pods must communicate with each other without NAT, we would need \(n(n-1)/2\) <em>veth</em> pairs, where \(n\) is the number of namespaces. This becomes unwieldy pretty quickly. We will use a <a href="https://wiki.linuxfoundation.org/networking/bridge">bridge</a> instead to solve this problem. A bridge lets us connect any number of devices to it and will happily route traffic between them, turning our architecture into a hub-and-spoke and reducing the number of <em>veth</em> pairs to just \(n\).</p><blockquote class="prompt-tip"><div><p><strong>Hands On</strong></p><details> <summary>On the “client” host</summary><div><div class="language-shell highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
</pre><td class="rouge-code"><pre><span class="c"># create a bridge</span>
root@kind-control-plane:/# ip <span class="nb">link </span>add bridge <span class="nb">type </span>bridge

<span class="c"># create veth pairs</span>
root@kind-control-plane:/# ip <span class="nb">link </span>add veth-client <span class="nb">type </span>veth peer name veth-clientbr
root@kind-control-plane:/# ip <span class="nb">link </span>add veth-server <span class="nb">type </span>veth peer name veth-serverbr

<span class="c"># connect one end of the veth devices to the bridge</span>
root@kind-control-plane:/# ip <span class="nb">link set </span>veth-clientbr master bridge
root@kind-control-plane:/# ip <span class="nb">link set </span>veth-serverbr master bridge

<span class="c"># attach the other end of the veth devices to their respective namespaces</span>
root@kind-control-plane:/# ip <span class="nb">link set </span>veth-client netns client 
root@kind-control-plane:/# ip <span class="nb">link set </span>veth-server netns server 

<span class="c"># assign IP addresses to the bridge and our new interfaces inside the client and server namespaces</span>
root@kind-control-plane:/# ip netns <span class="nb">exec </span>client ip addr add 10.0.0.1/24 dev veth-client
root@kind-control-plane:/# ip netns <span class="nb">exec </span>server ip addr add 10.0.0.2/24 dev veth-server
root@kind-control-plane:/# ip addr add 10.0.0.0/24 dev bridge

<span class="c"># bring our devices up</span>
root@kind-control-plane:/# ip netns <span class="nb">exec </span>client ip <span class="nb">link set </span>veth-client up
root@kind-control-plane:/# ip netns <span class="nb">exec </span>server ip <span class="nb">link set </span>veth-server up
root@kind-control-plane:/# ip <span class="nb">link set </span>veth-clientbr up
root@kind-control-plane:/# ip <span class="nb">link set </span>veth-serverbr up
root@kind-control-plane:/# ip <span class="nb">link set </span>bridge up

<span class="c"># confirm state of our interfaces:</span>
<span class="c"># state of client interfaces</span>
root@kind-control-plane:/# ip netns <span class="nb">exec </span>client ip addr
1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    <span class="nb">link</span>/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host
       valid_lft forever preferred_lft forever
16: veth-client@if15: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000
    <span class="nb">link</span>/ether 5e:0e:50:4b:f5:32 brd ff:ff:ff:ff:ff:ff link-netnsid 0
    inet 10.0.0.1/24 scope global veth-client
       valid_lft forever preferred_lft forever
    inet6 fe80::5c0e:50ff:fe4b:f532/64 scope <span class="nb">link
       </span>valid_lft forever preferred_lft forever

<span class="c"># state of server interfaces</span>
root@kind-control-plane:/# ip netns <span class="nb">exec </span>server ip addr
...
18: veth-server@if17: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000
    <span class="nb">link</span>/ether 46:d0:61:5d:7c:9a brd ff:ff:ff:ff:ff:ff link-netnsid 0
    inet 10.0.0.2/24 scope global veth-server
       valid_lft forever preferred_lft forever
    inet6 fe80::44d0:61ff:fe5d:7c9a/64 scope <span class="nb">link
       </span>valid_lft forever preferred_lft forever

<span class="c"># state of host interfaces</span>
root@kind-control-plane:/# ip addr     
...
11: eth0@if12: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default
    <span class="nb">link</span>/ether 02:42:ac:12:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0
    inet 172.18.0.2/16 brd 172.18.255.255 scope global eth0
       valid_lft forever preferred_lft forever
    inet6 fc00:f853:ccd:e793::2/64 scope global nodad
       valid_lft forever preferred_lft forever
    inet6 fe80::42:acff:fe12:2/64 scope <span class="nb">link
       </span>valid_lft forever preferred_lft forever
14: bridge: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000
    <span class="nb">link</span>/ether ba:21:cf:c1:62:52 brd ff:ff:ff:ff:ff:ff
    inet 10.0.0.0/24 scope global bridge
       valid_lft forever preferred_lft forever
15: veth-clientbr@if16: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master bridge state UP group default qlen 1000
    <span class="nb">link</span>/ether ba:21:cf:c1:62:52 brd ff:ff:ff:ff:ff:ff link-netns client
17: veth-serverbr@if18: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master bridge state UP group default qlen 1000
    <span class="nb">link</span>/ether c2:52:97:04:03:2c brd ff:ff:ff:ff:ff:ff link-netns server

<span class="c"># test connectivity</span>
root@kind-control-plane:/# ip netns <span class="nb">exec </span>client curl <span class="nt">-v</span> 10.0.0.2:8080
&lt;<span class="o">!</span>DOCTYPE HTML PUBLIC <span class="s2">"-//W3C//DTD HTML 4.01//EN"</span> <span class="s2">"http://www.w3.org/TR/html4/strict.dtd"</span><span class="o">&gt;</span>
&lt;html&gt;
&lt;<span class="nb">head</span><span class="o">&gt;</span>
&lt;meta http-equiv<span class="o">=</span><span class="s2">"Content-Type"</span> <span class="nv">content</span><span class="o">=</span><span class="s2">"text/html; charset=utf-8"</span><span class="o">&gt;</span>
&lt;title&gt;Directory listing <span class="k">for</span> /&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;h1&gt;Directory listing <span class="k">for</span> /&lt;/h1&gt;
&lt;hr&gt;
&lt;ul&gt;
...
&lt;/ul&gt;
&lt;hr&gt;
&lt;/body&gt;
&lt;/html&gt;
</pre></table></code></div></div></div></details></div></blockquote><p>At this point the whole setup looks like this:</p><p><img data-src="/assets/img/k8s-networking/pods-bridge.svg" alt="pods-bridge" data-proofer-ignore> <em>Two linux <code class="language-plaintext highlighter-rouge">net</code> namespaces connected to each other via a bridge. Note that although the bridge is connected to the host’s interface (<code class="language-plaintext highlighter-rouge">eth0</code>), traffic between the namespaces bypasses it entirely.</em></p><p>We have just connected two network namespaces on the same host.</p><h2 id="connecting-network-namespaces-on-different-hosts"><span class="mr-2">Connecting network namespaces on different hosts</span><a href="#connecting-network-namespaces-on-different-hosts" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><p>The only way in and out of our hosts in our example above is via their <code class="language-plaintext highlighter-rouge">eth0</code> interface. For outbound traffic, the packets first need to reach <code class="language-plaintext highlighter-rouge">eth0</code> before being forwarded to the physical network. For inbound packets, <code class="language-plaintext highlighter-rouge">eth0</code> needs to forward those to the bridge where they will be routed to the respective namespace interfaces. Let’s first separate our two namespaces before going further.</p><h3 id="moving-our-network-namespaces-onto-different-hosts"><span class="mr-2">Moving our network namespaces onto different hosts</span><a href="#moving-our-network-namespaces-onto-different-hosts" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><p>Let’s first clean up everything we’ve done so far<sup id="fnref:7" role="doc-noteref"><a href="#fn:7" class="footnote" rel="footnote">4</a></sup>:</p><blockquote class="prompt-tip"><div><p><strong>Hands On</strong></p><details> <summary>Steps</summary><div><div class="language-shell highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre><span class="c"># delete the namespaces</span>
root@kind-control-plane:/# ip netns del client
root@kind-control-plane:/# ip netns del server

<span class="c"># delete the veth and bridge devices</span>
root@kind-control-plane:/# ip <span class="nb">link </span>del veth-client
root@kind-control-plane:/# ip <span class="nb">link </span>del veth-server
root@kind-control-plane:/# ip <span class="nb">link </span>del bridge
</pre></table></code></div></div></div></details></div></blockquote><p>Let’s now set up our namespaces in different hosts.</p><blockquote class="prompt-tip"><div><p><strong>Hands On</strong></p><p>Same steps as before except on different hosts with some minor differences:</p><details> <summary>On the “client” host</summary><div><div class="language-shell highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre><td class="rouge-code"><pre>root@kind-control-plane:/# ip netns add client
root@kind-control-plane:/# ip <span class="nb">link </span>add bridge <span class="nb">type </span>bridge
root@kind-control-plane:/# ip <span class="nb">link </span>add veth-client <span class="nb">type </span>veth peer name veth-clientbr
root@kind-control-plane:/# ip <span class="nb">link set </span>veth-client netns client
root@kind-control-plane:/# ip <span class="nb">link set </span>veth-clientbr master bridge
root@kind-control-plane:/# ip addr add 10.0.0.0/24 dev bridge
root@kind-control-plane:/# ip netns <span class="nb">exec </span>client ip addr add 10.0.0.1/24 dev veth-client
root@kind-control-plane:/# ip netns <span class="nb">exec </span>client ip <span class="nb">link set </span>lo up
root@kind-control-plane:/# ip netns <span class="nb">exec </span>client ip <span class="nb">link set </span>veth-client up
root@kind-control-plane:/# ip <span class="nb">link set </span>bridge up
root@kind-control-plane:/# ip <span class="nb">link set </span>veth-clientbr up
</pre></table></code></div></div></div></details> <details> <summary>On the “server” host</summary><div><div class="language-shell highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
</pre><td class="rouge-code"><pre>root@kind-worker:/# ip netns add server
root@kind-worker:/# ip <span class="nb">link </span>add bridge <span class="nb">type </span>bridge
root@kind-worker:/# ip <span class="nb">link </span>add veth-server <span class="nb">type </span>veth peer name veth-serverbr
root@kind-worker:/# ip <span class="nb">link set </span>veth-server netns server
root@kind-worker:/# ip <span class="nb">link set </span>veth-serverbr master bridge
root@kind-worker:/# ip addr add 10.0.0.0/24 dev bridge
root@kind-worker:/# ip netns <span class="nb">exec </span>server ip addr add 10.0.0.2/24 dev veth-server
root@kind-worker:/# ip netns <span class="nb">exec </span>server ip <span class="nb">link set </span>lo up
root@kind-worker:/# ip netns <span class="nb">exec </span>server ip <span class="nb">link set </span>veth-server up
root@kind-worker:/# ip <span class="nb">link set </span>bridge up
root@kind-worker:/# ip <span class="nb">link set </span>veth-serverbr up

<span class="c"># run the server</span>
root@kind-worker:/# ip netns <span class="nb">exec </span>server <span class="nb">nohup </span>python3 <span class="nt">-m</span> http.server 8080 &amp;
<span class="o">[</span>1] 1314
<span class="nb">nohup</span>: ignoring input and appending output to <span class="s1">'nohup.out'</span>
</pre></table></code></div></div></div></details></div></blockquote><p><img data-src="/assets/img/k8s-networking/pods-diffhosts.svg" alt="pod-different-hosts" data-proofer-ignore> <em>Namespaces on different hosts. The host interfaces (<code class="language-plaintext highlighter-rouge">eth0</code>) are on the same network.</em></p><p>Now that everything is set up, let’s first tackle outbound traffic.</p><h3 id="from-our-network-namespaces-to-the-physical-network"><span class="mr-2">From our network namespaces to the physical network</span><a href="#from-our-network-namespaces-to-the-physical-network" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><p>First let’s see if we can reach <code class="language-plaintext highlighter-rouge">eth0</code> on each host:</p><div class="language-shell highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre><span class="c"># on the client host</span>
root@kind-control-plane:/# ip netns <span class="nb">exec </span>client ping 172.18.0.2
ping: connect: Network is unreachable

<span class="c"># on the server host</span>
root@kind-worker:/# ip netns <span class="nb">exec </span>server ping 172.18.0.4
ping: connect: Network is unreachable
</pre></table></code></div></div><p>The host isn’t reachable from the namespaces yet. <em>We haven’t configured an IP route<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">5</a></sup> to forward packets destined to <code class="language-plaintext highlighter-rouge">eth0</code> in neither host.</em> Let’s set up a default route via the bridge in both namespaces and test:</p><div class="language-shell highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
</pre><td class="rouge-code"><pre><span class="c"># on client host</span>
root@kind-control-plane:/# ip netns <span class="nb">exec </span>client ip route add default via 10.0.0.0
root@kind-control-plane:/# ip netns <span class="nb">exec </span>client ping 172.18.0.2 <span class="nt">-c</span> 2
PING 172.18.0.2 <span class="o">(</span>172.18.0.2<span class="o">)</span> 56<span class="o">(</span>84<span class="o">)</span> bytes of data.
64 bytes from 172.18.0.2: <span class="nv">icmp_seq</span><span class="o">=</span>1 <span class="nv">ttl</span><span class="o">=</span>64 <span class="nb">time</span><span class="o">=</span>0.076 ms
64 bytes from 172.18.0.2: <span class="nv">icmp_seq</span><span class="o">=</span>2 <span class="nv">ttl</span><span class="o">=</span>64 <span class="nb">time</span><span class="o">=</span>0.039 ms

<span class="nt">---</span> 172.18.0.2 ping statistics <span class="nt">---</span>
2 packets transmitted, 2 received, 0% packet loss, <span class="nb">time </span>1031ms
rtt min/avg/max/mdev <span class="o">=</span> 0.039/0.057/0.076/0.018 ms

<span class="c"># on server host</span>
root@kind-worker:/# ip netns <span class="nb">exec </span>server ip route add default via 10.0.0.0
root@kind-worker:/# ip netns <span class="nb">exec </span>server ping 172.18.0.4 <span class="nt">-c</span> 2
PING 172.18.0.4 <span class="o">(</span>172.18.0.4<span class="o">)</span> 56<span class="o">(</span>84<span class="o">)</span> bytes of data.
64 bytes from 172.18.0.4: <span class="nv">icmp_seq</span><span class="o">=</span>1 <span class="nv">ttl</span><span class="o">=</span>64 <span class="nb">time</span><span class="o">=</span>0.036 ms
64 bytes from 172.18.0.4: <span class="nv">icmp_seq</span><span class="o">=</span>2 <span class="nv">ttl</span><span class="o">=</span>64 <span class="nb">time</span><span class="o">=</span>0.035 ms

<span class="nt">---</span> 172.18.0.4 ping statistics <span class="nt">---</span>
2 packets transmitted, 2 received, 0% packet loss, <span class="nb">time </span>1031ms
rtt min/avg/max/mdev <span class="o">=</span> 0.035/0.035/0.036/0.000 ms
</pre></table></code></div></div><p>Great, we can now reach our host interfaces. By extension, we can also reach any destination reachable from <code class="language-plaintext highlighter-rouge">eth0</code>:</p><div class="language-shell highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</pre><td class="rouge-code"><pre><span class="c"># on client host</span>
root@kind-control-plane:/# ip netns <span class="nb">exec </span>client curl https://google.com
&lt;HTML&gt;&lt;HEAD&gt;&lt;meta http-equiv<span class="o">=</span><span class="s2">"content-type"</span> <span class="nv">content</span><span class="o">=</span><span class="s2">"text/html;charset=utf-8"</span><span class="o">&gt;</span>
&lt;TITLE&gt;301 Moved&lt;/TITLE&gt;&lt;/HEAD&gt;&lt;BODY&gt;
&lt;H1&gt;301 Moved&lt;/H1&gt;
The document has moved
&lt;A <span class="nv">HREF</span><span class="o">=</span><span class="s2">"https://www.google.com/"</span><span class="o">&gt;</span>here&lt;/A&gt;.
&lt;/BODY&gt;&lt;/HTML&gt;

<span class="c"># on server host</span>
root@kind-worker:/# ip netns <span class="nb">exec </span>server curl https://google.com
&lt;HTML&gt;&lt;HEAD&gt;&lt;meta http-equiv<span class="o">=</span><span class="s2">"content-type"</span> <span class="nv">content</span><span class="o">=</span><span class="s2">"text/html;charset=utf-8"</span><span class="o">&gt;</span>
&lt;TITLE&gt;301 Moved&lt;/TITLE&gt;&lt;/HEAD&gt;&lt;BODY&gt;
&lt;H1&gt;301 Moved&lt;/H1&gt;
The document has moved
&lt;A <span class="nv">HREF</span><span class="o">=</span><span class="s2">"https://www.google.com/"</span><span class="o">&gt;</span>here&lt;/A&gt;.
&lt;/BODY&gt;&lt;/HTML&gt;
</pre></table></code></div></div><p>This flow looks similar to the following when viewed from the <code class="language-plaintext highlighter-rouge">client</code> flow (Google’s infrastructure has been vastly simplified):</p><p><img data-src="/assets/img/k8s-networking/pods-outbound.svg" alt="pods-outbound.svg" data-proofer-ignore></p><p>Next up, let’s try to communicate to our server from the <code class="language-plaintext highlighter-rouge">client</code> namespace.</p><h3 id="from-the-physical-network-to-our-network-namespaces"><span class="mr-2">From the physical network to our network namespaces</span><a href="#from-the-physical-network-to-our-network-namespaces" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><p>If we try to reach <code class="language-plaintext highlighter-rouge">server</code> from <code class="language-plaintext highlighter-rouge">client</code> we can see that it doesn’t work:</p><div class="language-shell highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>root@kind-control-plane:/# ip netns <span class="nb">exec </span>client curl <span class="nt">-m</span> 2 10.0.0.2:8080
curl: <span class="o">(</span>28<span class="o">)</span> Connection timed out after 2001 milliseconds
</pre></table></code></div></div><p>Let’s dig in with <code class="language-plaintext highlighter-rouge">tcpdump</code>.</p><p>Open a terminal window and, since we aren’t sure what path the packets are flowing through, run <code class="language-plaintext highlighter-rouge">tcpdump -nn -e -l -i any</code> on host <code class="language-plaintext highlighter-rouge">172.18.0.2</code>. <strong>Friendly warning:</strong> the output will be very verbose because <code class="language-plaintext highlighter-rouge">tcpdump</code> will listen on <em>all</em> interfaces.</p><p>On the same host <code class="language-plaintext highlighter-rouge">172.18.0.2</code>, try to curl the server from the <code class="language-plaintext highlighter-rouge">client</code> namespace again with <code class="language-plaintext highlighter-rouge">ip netns exec client curl -m 2 10.0.0.2:8080</code>. After it times out again, stop <code class="language-plaintext highlighter-rouge">tcpdump</code> by pressing <code class="language-plaintext highlighter-rouge">Ctrl+C</code> and review the output. Search for <code class="language-plaintext highlighter-rouge">10.0.0.2</code>, our destination address. You should spot some lines like the following:</p><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>15:05:35.754605 bridge Out ifindex 5 a6:93:c7:0c:96:b2 ethertype ARP (0x0806), length 48: Request who-has 10.0.0.2 tell 10.0.0.0, length 28
15:05:35.754608 veth-clientbr Out ifindex 6 a6:93:c7:0c:96:b2 ethertype ARP (0x0806), length 48: Request who-has 10.0.0.2 tell 10.0.0.0, length 28
</pre></table></code></div></div><p>You may see several of these requests with no corresponding reply<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote" rel="footnote">6</a></sup>.</p><p>These are <a href="https://en.wikipedia.org/wiki/Address_Resolution_Protocol">ARP</a> requests, and the reason they’re being fired off is that there is no [IP (<a href="https://en.wikipedia.org/wiki/Network_layer">layer 3</a>)] route between the <code class="language-plaintext highlighter-rouge">client</code> and <code class="language-plaintext highlighter-rouge">server</code> namespaces. It is possible to <a href="https://www.xmodulo.com/how-to-add-or-remove-static-arp-entry-on-linux.html">manually configure ARP entries</a> and implement <a href="https://tldp.org/HOWTO/Adv-Routing-HOWTO/lartc.bridging.proxy-arp.html">“proxy-ARP”</a> to connect <code class="language-plaintext highlighter-rouge">client</code> and <code class="language-plaintext highlighter-rouge">server</code> at <a href="https://en.wikipedia.org/wiki/Data_link_layer">Layer 2</a>, but we are not doing that today. Kubernetes’ networking model is built on Layer 3 and up, and so must our solution.</p><p>We will configure IP routing<sup id="fnref:2:1" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">5</a></sup> rules to route <code class="language-plaintext highlighter-rouge">client</code> traffic to <code class="language-plaintext highlighter-rouge">server</code>. Let’s first configure a manual route for <code class="language-plaintext highlighter-rouge">10.0.0.2</code> on the client host:</p><div class="language-shell highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
</pre><td class="rouge-code"><pre><span class="c"># on client host</span>
root@kind-control-plane:/# ip route add 10.0.0.2 via 172.18.0.4

<span class="c"># validate</span>
root@kind-control-plane:/# curl 10.0.0.2:8080
&lt;<span class="o">!</span>DOCTYPE HTML PUBLIC <span class="s2">"-//W3C//DTD HTML 4.01//EN"</span> <span class="s2">"http://www.w3.org/TR/html4/strict.dtd"</span><span class="o">&gt;</span>
&lt;html&gt;
&lt;<span class="nb">head</span><span class="o">&gt;</span>
&lt;meta http-equiv<span class="o">=</span><span class="s2">"Content-Type"</span> <span class="nv">content</span><span class="o">=</span><span class="s2">"text/html; charset=utf-8"</span><span class="o">&gt;</span>
&lt;title&gt;Directory listing <span class="k">for</span> /&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;h1&gt;Directory listing <span class="k">for</span> /&lt;/h1&gt;
&lt;hr&gt;
&lt;ul&gt;
...
&lt;/ul&gt;
&lt;hr&gt;
&lt;/body&gt;
&lt;/html&gt;
</pre></table></code></div></div><p>As you can see, <code class="language-plaintext highlighter-rouge">curl</code>‘ing our server API in the <code class="language-plaintext highlighter-rouge">server</code> namespace from the client <em>host</em> now works<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" class="footnote" rel="footnote">7</a></sup>.</p><p>Let’s try <code class="language-plaintext highlighter-rouge">curl</code>‘ing the server from the <code class="language-plaintext highlighter-rouge">client</code> <em>namespace</em> again:</p><div class="language-shell highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>root@kind-control-plane:/# ip netns <span class="nb">exec </span>client curl <span class="nt">-m</span> 2 10.0.0.2:8080
curl: <span class="o">(</span>28<span class="o">)</span> Connection timed out after 2001 milliseconds
</pre></table></code></div></div><p>Another dump with <code class="language-plaintext highlighter-rouge">tcpdump</code> reveals the same unanswered <code class="language-plaintext highlighter-rouge">ARP</code> requests as before. Why aren’t there responses to these considering we’ve successfully established a connection from the client <em>host</em> to the <code class="language-plaintext highlighter-rouge">server</code> namespace? One reason is that the connection was made at layer 3 (IP route), but <code class="language-plaintext highlighter-rouge">ARP</code> is a layer 2 protocol, and as per the <a href="https://en.wikipedia.org/wiki/OSI_model">OSI model’s</a> semantics, lower-level protocols cannot depend on higher-level ones. Another reason is that <code class="language-plaintext highlighter-rouge">ARP</code> messages only reach devices directly connected to our network interface, in this case <code class="language-plaintext highlighter-rouge">eth0</code>: the latter’s <code class="language-plaintext highlighter-rouge">ARP</code> table does not contain an entry for <code class="language-plaintext highlighter-rouge">10.0.0.2</code> even though its namespace’s <em>IP routing</em> table does.</p><p>The layer 3 solution for us is simple: establish another IP route for <code class="language-plaintext highlighter-rouge">10.0.0.2</code> inside the <code class="language-plaintext highlighter-rouge">client</code> namespace<sup id="fnref:5" role="doc-noteref"><a href="#fn:5" class="footnote" rel="footnote">8</a></sup>:</p><div class="language-shell highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>root@kind-control-plane:/# ip netns <span class="nb">exec </span>client ip route add 10.0.0.2 via 10.0.0.0
</pre></table></code></div></div><p>You can now verify that calling <code class="language-plaintext highlighter-rouge">server</code> from <code class="language-plaintext highlighter-rouge">client</code> works:</p><div class="language-shell highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
</pre><td class="rouge-code"><pre>root@kind-control-plane:/# ip netns <span class="nb">exec </span>client curl <span class="nt">-m</span> 2 10.0.0.2:8080
&lt;<span class="o">!</span>DOCTYPE HTML PUBLIC <span class="s2">"-//W3C//DTD HTML 4.01//EN"</span> <span class="s2">"http://www.w3.org/TR/html4/strict.dtd"</span><span class="o">&gt;</span>
&lt;html&gt;
&lt;<span class="nb">head</span><span class="o">&gt;</span>
&lt;meta http-equiv<span class="o">=</span><span class="s2">"Content-Type"</span> <span class="nv">content</span><span class="o">=</span><span class="s2">"text/html; charset=utf-8"</span><span class="o">&gt;</span>
&lt;title&gt;Directory listing <span class="k">for</span> /&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;h1&gt;Directory listing <span class="k">for</span> /&lt;/h1&gt;
&lt;hr&gt;
&lt;ul&gt;
...
&lt;/ul&gt;
&lt;hr&gt;
&lt;/body&gt;
&lt;/html&gt;
</pre></table></code></div></div><p><strong>Congratulations 🎉 🎉</strong> - we have just manually created two Pods (<code class="language-plaintext highlighter-rouge">net</code> namespaces) on different hosts, with one “container” (<code class="language-plaintext highlighter-rouge">curl</code>) in one Pod invoking an API in a container in the other Pod without NAT.</p><p><img data-src="/assets/img/k8s-networking/pod2pod-diff-hosts.svg" alt="pod-pod-hosts" data-proofer-ignore> <em>A process inside a <code class="language-plaintext highlighter-rouge">client</code> namespace connecting to an open socket on a <code class="language-plaintext highlighter-rouge">server</code> namespace in another host. The client process does not perform any NAT.</em></p><h2 id="how-kubernetes-creates-pods"><span class="mr-2">How Kubernetes creates Pods</span><a href="#how-kubernetes-creates-pods" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><p>We now know how pods are implemented under the hood. We have learned that Kubernetes “pods” are namespaces and that Kubernetes “containers” are processes running within those namespaces. These pods are connected to each other within each host with virtual networking devices (<code class="language-plaintext highlighter-rouge">veth</code>, <code class="language-plaintext highlighter-rouge">bridge</code>), and with simple IP routing rules for traffic to cross from one pod to another over the physical network.</p><p>Where and how does Kubernetes do all this?</p><h3 id="the-container-runtime-interface-cri"><span class="mr-2">The Container Runtime Interface (CRI)</span><a href="#the-container-runtime-interface-cri" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><p>Back in the <a href="#concepts">concepts section</a> we said the <code class="language-plaintext highlighter-rouge">kubelet</code> uses the <a href="https://github.com/kubernetes/cri-api">Container Runtime Interface</a> to create the pod “sandboxes”.</p><p>The <code class="language-plaintext highlighter-rouge">kubelet</code> creates pod sandboxes <a href="https://github.com/kubernetes/kubernetes/blob/67b38ffe6ea3350f3cefd72caacd3f7ee9b1af42/pkg/kubelet/kuberuntime/kuberuntime_sandbox.go#L68-L73">here</a>. Note that <code class="language-plaintext highlighter-rouge">runtimeService</code> is of type <a href="https://github.com/kubernetes/cri-api/blob/adbbc6d75b383d6b823c24bba946029458d6681b/pkg/apis/services.go#L106-L118"><code class="language-plaintext highlighter-rouge">RuntimeService</code></a>, belonging to the CRI API. It embeds the <code class="language-plaintext highlighter-rouge">PodSandboxManager</code> type, which is responsible for actually creating the sandboxes (<code class="language-plaintext highlighter-rouge">RunPodSandbox</code> method). Kubernetes has an internal implementation of <code class="language-plaintext highlighter-rouge">RuntimeService</code> in <a href="https://github.com/kubernetes/kubernetes/blob/805be30745defc72cb6137a25b3e821db4056837/pkg/kubelet/cri/remote/remote_runtime.go#L45-L52"><code class="language-plaintext highlighter-rouge">remoteRuntimeService</code></a>, but this is just a thin wrapper around the CRI API’s <a href="https://github.com/kubernetes/cri-api/blob/adbbc6d75b383d6b823c24bba946029458d6681b/pkg/apis/runtime/v1/api.pb.go#L10076-L10168"><code class="language-plaintext highlighter-rouge">RuntimeServiceClient</code></a> (GitHub won’t automatically open the file due to its size). Look closely and you’ll notice that <code class="language-plaintext highlighter-rouge">RuntimeServiceClient</code> is implemented by <a href="https://github.com/kubernetes/cri-api/blob/adbbc6d75b383d6b823c24bba946029458d6681b/pkg/apis/runtime/v1/api.pb.go#L10170-L10172"><code class="language-plaintext highlighter-rouge">runtimeServiceClient</code></a>, which uses a <a href="https://grpc.io/">gRPC</a> connection to invoke the container runtime service. gRPC is (normally) transported over TCP sockets (<a href="https://en.wikipedia.org/wiki/Transport_layer">Layer 3</a>).</p><p>The <code class="language-plaintext highlighter-rouge">kubelet</code> runs on each node and, if it needs to create a pod on that node, why would it need to communicate with the CRI service over TCP?</p><p>Go, the <em>lingua franca</em> of cloud-native development (including Kubernetes), has a builtin <a href="https://pkg.go.dev/plugin"><code class="language-plaintext highlighter-rouge">plugin</code></a> system but it has some serious drawbacks in terms of maintainability. Eli Bendersky gives a good outline of how they work with pros and cons <a href="https://eli.thegreenplace.net/2021/plugins-in-go/">here</a> that is worth a read. Towards the end of the article you’ll notice a bias towards RPC-based plugins; this is exactly what the CRI’s designers chose as their architecture. So although the <code class="language-plaintext highlighter-rouge">kubelet</code> and the CRI service are running on the same node, the gRPC messages can be transported locally via <code class="language-plaintext highlighter-rouge">localhost</code> (for TCP) or <a href="https://en.wikipedia.org/wiki/Unix_domain_socket">Unix domain sockets</a> or some other channel available on the host.</p><p>So we now have Kubernetes invoking the standard CRI API that in turn invokes a “remote”, CRI-compliant gRPC service. This service is the CRI implementation that can be swapped out. Kubernetes’ docs list <a href="https://kubernetes.io/docs/setup/production-environment/container-runtimes/">a few common ones</a>:</p><ul><li><a href="https://github.com/containerd/containerd">containerd</a><li><a href="https://github.com/cri-o/cri-o">CRI-O</a><li><a href="https://github.com/moby/moby">Docker Engine</a><li><a href="https://github.com/Mirantis/cri-dockerd">Mirantis Container Runtime</a></ul><p>The details of what happens next vary by implementation, and is all abstracted away from the Kubernetes runtime. Take <code class="language-plaintext highlighter-rouge">containerd</code> as an example (it’s the CRI used in <a href="https://github.com/kubernetes-sigs/kind">kind</a>, the K8S distribution I chose for the <a href="#create-your-own-pod-network">walkthrough</a> above). <code class="language-plaintext highlighter-rouge">containerd</code> has a plugin architecture that is resolved at compile time<sup id="fnref:8" role="doc-noteref"><a href="#fn:8" class="footnote" rel="footnote">9</a></sup>. <code class="language-plaintext highlighter-rouge">containerd</code>’s <a href="https://github.com/containerd/containerd/blob/a338abc902d9f204dcb9df7212d39fd7d07ac06d/pkg/cri/server/service.go#L78-L128">implementation</a> of <code class="language-plaintext highlighter-rouge">RuntimeServiceServer</code> (part of <a href="#concepts">Concepts</a>) has its <a href="https://github.com/containerd/containerd/blob/3ee6dd5c1bca441d1ec4988cbaebadbfbcfde525/pkg/cri/server/sandbox_run.go#L56-L407"><code class="language-plaintext highlighter-rouge">RunPodSandbox</code></a> method (also part of <a href="#concepts">Concepts</a>) rely on a “CNI” plugin to set up the pod’s network namespace.</p><p>What is the CNI?</p><h3 id="the-container-network-interface-cni"><span class="mr-2">The Container Network Interface (CNI)</span><a href="#the-container-network-interface-cni" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><p>The <a href="https://github.com/containernetworking/cni">CNI</a> is used by the CRI to create and configure the network namespaces used by the pods<sup id="fnref:9" role="doc-noteref"><a href="#fn:9" class="footnote" rel="footnote">10</a></sup>. CNI implementations are invoked by executing their respective binaries and providing network configuration via <code class="language-plaintext highlighter-rouge">stdin</code> (see the spec’s <a href="https://github.com/containernetworking/cni/blob/main/SPEC.md#section-2-execution-protocol">execution protocol</a>)<sup id="fnref:10" role="doc-noteref"><a href="#fn:10" class="footnote" rel="footnote">11</a></sup>. On unix hosts, <code class="language-plaintext highlighter-rouge">containerd</code> by default looks for a standard CNI config file inside the <code class="language-plaintext highlighter-rouge">/etc/cni/net.d</code> directory and for the plugin binaries it looks in <code class="language-plaintext highlighter-rouge">/opt/cni/bin</code> (see <a href="https://github.com/containerd/containerd/blob/3bc8fc4d3067c32d2580e716af095a837c0fbe9a/pkg/cri/config/config_unix.go#L68-L69">code</a>). Each node in my <code class="language-plaintext highlighter-rouge">kind</code> cluster has only one config file: <code class="language-plaintext highlighter-rouge">/etc/cni/net.d/10-kindnet.conflist</code>. Here are the contents of this file in my <code class="language-plaintext highlighter-rouge">control-plane</code> node:</p><details> <summary>Click to expand</summary><div><div class="language-json highlighter-rouge"><div class="code-header"> <span data-label-text="JSON"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
</pre><td class="rouge-code"><pre><span class="p">{</span><span class="w">
  </span><span class="nl">"cniVersion"</span><span class="p">:</span><span class="w"> </span><span class="s2">"0.3.1"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"kindnet"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"plugins"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
    </span><span class="p">{</span><span class="w">
      </span><span class="nl">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"ptp"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"ipMasq"</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span><span class="p">,</span><span class="w">
      </span><span class="nl">"ipam"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="nl">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"host-local"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"dataDir"</span><span class="p">:</span><span class="w"> </span><span class="s2">"/run/cni-ipam-state"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"routes"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
          </span><span class="p">{</span><span class="w">
            </span><span class="nl">"dst"</span><span class="p">:</span><span class="w"> </span><span class="s2">"0.0.0.0/0"</span><span class="w">
          </span><span class="p">}</span><span class="w">
        </span><span class="p">],</span><span class="w">
        </span><span class="nl">"ranges"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
          </span><span class="p">[</span><span class="w">
            </span><span class="p">{</span><span class="w">
              </span><span class="nl">"subnet"</span><span class="p">:</span><span class="w"> </span><span class="s2">"10.244.0.0/24"</span><span class="w">
            </span><span class="p">}</span><span class="w">
          </span><span class="p">]</span><span class="w">
        </span><span class="p">]</span><span class="w">
      </span><span class="p">},</span><span class="w">
      </span><span class="nl">"mtu"</span><span class="p">:</span><span class="w"> </span><span class="mi">1500</span><span class="w">
    </span><span class="p">},</span><span class="w">
    </span><span class="p">{</span><span class="w">
      </span><span class="nl">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"portmap"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"capabilities"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="nl">"portMappings"</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
      </span><span class="p">}</span><span class="w">
    </span><span class="p">}</span><span class="w">
  </span><span class="p">]</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></pre></table></code></div></div></div></details><p>The same config file on the worker nodes have identical content except for <code class="language-plaintext highlighter-rouge">subnet</code>, which varies from host to host. I won’t go in depth about how the CNI spec and plugins work (that deserves its own article). You can read version <code class="language-plaintext highlighter-rouge">0.3.1</code> of the spec <a href="https://github.com/containernetworking/cni/blob/spec-v0.3.1/SPEC.md">here</a>. What’s conceptually important for us is that there are three plugins being executed (two of them are chained) with this configuration. These plugins are:</p><ul><li><a href="https://www.cni.dev/plugins/current/main/ptp/">ptp</a>: creates a point-to-point link between a container and the host by using a veth device.<li><a href="https://www.cni.dev/plugins/current/ipam/host-local/">host-local</a>: allocates IPv4 and IPv6 addresses out of a specified address range.<li><a href="https://www.cni.dev/plugins/current/meta/portmap/">portmap</a>: will forward traffic from one or more ports on the host to the container.</ul><p>Do any of these concepts sound familiar to you? They should!<sup id="fnref:12" role="doc-noteref"><a href="#fn:12" class="footnote" rel="footnote">12</a></sup> These are the things we painstakingly configured step-by-step in our walkthrough above. With this information in mind, go back to the component diagram in <a href="#concepts">Concepts</a> and map each of these concepts to the boxes in the diagram.</p><h1 id="services">Services</h1><p>No discussion of Kubernetes’ cluster network can conclude without mentioning <a href="https://kubernetes.io/docs/concepts/services-networking/service/">Services</a>.</p><p>Conceptually, a Kubernetes <em>Service</em> is merely a <a href="https://en.wikipedia.org/wiki/Virtual_IP_address">Virtual IP</a> assigned to a set of pods, and to which a stable <a href="https://en.wikipedia.org/wiki/Domain_Name_System">DNS name</a> is assigned. Kubernetes also provides simple load balancing out of the box for some types of services (<code class="language-plaintext highlighter-rouge">ClusterIP</code>, <code class="language-plaintext highlighter-rouge">NodePort</code>).</p><p>Each service is mapped to a set of IPs belonging to the pods exposed by the service. These set of IPs is called <a href="https://kubernetes.io/docs/concepts/services-networking/endpoint-slices/">EndpointSlice</a> and is constantly updated to reflect the IPs currently in use by the backend pods<sup id="fnref:13" role="doc-noteref"><a href="#fn:13" class="footnote" rel="footnote">13</a></sup>. Which pods? The ones matching the service’s <em>selector</em>.</p><details> <summary>Example Service with label ‘myLabel’ set to value ‘MyApp’</summary><div><div class="language-yaml highlighter-rouge"><div class="code-header"> <span data-label-text="YAML"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre><td class="rouge-code"><pre>  <span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
  <span class="na">kind</span><span class="pi">:</span> <span class="s">Service</span>
  <span class="na">metadata</span><span class="pi">:</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">my-service</span>
  <span class="na">spec</span><span class="pi">:</span>
    <span class="na">selector</span><span class="pi">:</span>
      <span class="na">myLabel</span><span class="pi">:</span> <span class="s">MyApp</span>
    <span class="na">ports</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">protocol</span><span class="pi">:</span> <span class="s">TCP</span>
        <span class="na">port</span><span class="pi">:</span> <span class="m">80</span>
        <span class="na">targetPort</span><span class="pi">:</span> <span class="m">9376</span>
</pre></table></code></div></div></div></details><p>When a user creates a new Service:</p><ol><li><code class="language-plaintext highlighter-rouge">kube-apiserver</code> assigns it the next free IP by incrementing a counter stored in <code class="language-plaintext highlighter-rouge">etcd</code><sup id="fnref:16" role="doc-noteref"><a href="#fn:16" class="footnote" rel="footnote">14</a></sup>.<li><code class="language-plaintext highlighter-rouge">kube-apiserver</code> stores the service in <code class="language-plaintext highlighter-rouge">etcd</code><sup id="fnref:17" role="doc-noteref"><a href="#fn:17" class="footnote" rel="footnote">15</a></sup>.<li>This event is pushed to all <a href="https://kubernetes.io/docs/reference/using-api/api-concepts/#efficient-detection-of-changes">watches</a><sup id="fnref:14" role="doc-noteref"><a href="#fn:14" class="footnote" rel="footnote">16</a></sup>.<li><code class="language-plaintext highlighter-rouge">coreDNS</code>:<ol><li>Event is caught and the service’s name, namespace, and (virtual) cluster IP is cached<sup id="fnref:18" role="doc-noteref"><a href="#fn:18" class="footnote" rel="footnote">17</a></sup>.<li>Responds to requests for A records by reading from the cache<sup id="fnref:19" role="doc-noteref"><a href="#fn:19" class="footnote" rel="footnote">18</a></sup>.</ol><li><a href="https://kubernetes.io/docs/concepts/services-networking/endpoint-slices/">EndpointSlice</a> Controller: event is caught and a new EndpointSlice is assigned to the service<sup id="fnref:20" role="doc-noteref"><a href="#fn:20" class="footnote" rel="footnote">19</a></sup>.<li><code class="language-plaintext highlighter-rouge">kube-proxy</code>: event is caught and <code class="language-plaintext highlighter-rouge">iptables</code> is configured on worker nodes<sup id="fnref:21" role="doc-noteref"><a href="#fn:21" class="footnote" rel="footnote">20</a></sup>.</ol><p>All steps from 4 onwards are executing concurrently by independent processes. The final state is depicted in the diagram in the <a href="#concepts">Concepts</a> section.</p><p>Note that we have incidentally glossed over Kubernetes’ distributed and event-driven architecture. We’ll expand on that topic in a future article.</p><p>We snuck in a new concept in step 6: <code class="language-plaintext highlighter-rouge">iptables</code>. Let’s expand on that next.</p><h2 id="iptables"><span class="mr-2">iptables</span><a href="#iptables" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><blockquote><p>Iptables is used to set up, maintain, and inspect the tables of IP packet filter rules in the Linux kernel. Several different tables may be defined. Each table contains a number of built-in chains and may also contain user-defined chains.</p><p>Each chain is a list of rules which can match a set of packets. Each rule specifies what to do with a packet that matches. This is called a `target’, which may be a jump to a user-defined chain in the same table.</p><p>– <code class="language-plaintext highlighter-rouge">iptables</code> manpage</p></blockquote><p>System and network administrators use <code class="language-plaintext highlighter-rouge">iptables</code> to configure IP routing rules on <em>Linux</em> hosts, and so does <code class="language-plaintext highlighter-rouge">kube-proxy</code><sup id="fnref:15" role="doc-noteref"><a href="#fn:15" class="footnote" rel="footnote">21</a></sup>. On <em>Windows</em> hosts <code class="language-plaintext highlighter-rouge">kube-proxy</code> uses an analogous API called <a href="https://learn.microsoft.com/en-us/windows-server/networking/technologies/hcn/hcn-top">Host Compute Network service API</a>, internally represented by the <a href="https://github.com/kubernetes/kubernetes/blob/5eb6f82c1ade7ceac0e9f26283d35ec806e47b9f/pkg/proxy/winkernel/hns.go#L33-L44">HostNetworkService</a> interface. It is because of this difference in OS-dependent implementations of the network stack that we simply labelled them as “OS IP rules” in the <a href="#concepts">Concepts</a> section’s diagram.</p><p><code class="language-plaintext highlighter-rouge">kube-proxy</code> uses <code class="language-plaintext highlighter-rouge">iptables</code> to configure Linux hosts to distribute traffic directed at a Service’s <code class="language-plaintext highlighter-rouge">clusterIP</code> (ie. a <em>virtual</em> IP) to the backend pods selected by the service using <a href="https://en.wikipedia.org/wiki/Network_address_translation">NAT</a>. So yes, there is definitely network address translation in a Kubernetes cluster, but it’s hidden from your workloads.</p><p><code class="language-plaintext highlighter-rouge">kube-proxy</code> adds a rule to the <code class="language-plaintext highlighter-rouge">PREROUTING</code> chain that targets a custom chain called <code class="language-plaintext highlighter-rouge">KUBE-SERVICES</code><sup id="fnref:22" role="doc-noteref"><a href="#fn:22" class="footnote" rel="footnote">22</a></sup>. The end result looks like this:</p><div class="language-shell highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre>root@kind-control-plane:/# iptables <span class="nt">-t</span> nat <span class="nt">-L</span> PREROUTING <span class="nt">-n</span> <span class="nt">-v</span>
Chain PREROUTING <span class="o">(</span>policy ACCEPT 18999 packets, 3902K bytes<span class="o">)</span>
 pkts bytes target     prot opt <span class="k">in     </span>out     <span class="nb">source               </span>destination         
18955 3898K KUBE-SERVICES  all  <span class="nt">--</span>  <span class="k">*</span>      <span class="k">*</span>       0.0.0.0/0            0.0.0.0/0            /<span class="k">*</span> kubernetes service portals <span class="k">*</span>/
</pre></table></code></div></div><p>Initially the <code class="language-plaintext highlighter-rouge">KUBE-SERVICES</code> chain contains rules just for the <code class="language-plaintext highlighter-rouge">NodePort</code> custom chain and several built-in services:</p><div class="language-shell highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre>root@kind-control-plane:/# iptables <span class="nt">-t</span> nat <span class="nt">-L</span> KUBE-SERVICES <span class="nt">-n</span> <span class="nt">-v</span>
Chain KUBE-SERVICES <span class="o">(</span>2 references<span class="o">)</span>
 pkts bytes target     prot opt <span class="k">in     </span>out     <span class="nb">source               </span>destination         
    0     0 KUBE-SVC-TCOU7JCQXEZGVUNU  udp  <span class="nt">--</span>  <span class="k">*</span>      <span class="k">*</span>       0.0.0.0/0            10.96.0.10           /<span class="k">*</span> kube-system/kube-dns:dns cluster IP <span class="k">*</span>/ udp dpt:53
    0     0 KUBE-SVC-ERIFXISQEP7F7OF4  tcp  <span class="nt">--</span>  <span class="k">*</span>      <span class="k">*</span>       0.0.0.0/0            10.96.0.10           /<span class="k">*</span> kube-system/kube-dns:dns-tcp cluster IP <span class="k">*</span>/ tcp dpt:53
    0     0 KUBE-SVC-JD5MR3NA4I4DYORP  tcp  <span class="nt">--</span>  <span class="k">*</span>      <span class="k">*</span>       0.0.0.0/0            10.96.0.10           /<span class="k">*</span> kube-system/kube-dns:metrics cluster IP <span class="k">*</span>/ tcp dpt:9153
    0     0 KUBE-SVC-NPX46M4PTMTKRN6Y  tcp  <span class="nt">--</span>  <span class="k">*</span>      <span class="k">*</span>       0.0.0.0/0            10.96.0.1            /<span class="k">*</span> default/kubernetes:https cluster IP <span class="k">*</span>/ tcp dpt:443
  417 25020 KUBE-NODEPORTS  all  <span class="nt">--</span>  <span class="k">*</span>      <span class="k">*</span>       0.0.0.0/0            0.0.0.0/0            /<span class="k">*</span> kubernetes service nodeports<span class="p">;</span> NOTE: this must be the last rule <span class="k">in </span>this chain <span class="k">*</span>/ ADDRTYPE match dst-type LOCAL
</pre></table></code></div></div><p>New rules are appended for each service by the Proxier’s <code class="language-plaintext highlighter-rouge">syncProxyRules</code> method and are written <a href="https://github.com/kubernetes/kubernetes/blob/b9bc0e5ac8032bb63298a407c287e6055ef073de/pkg/proxy/iptables/proxier.go#L1095-L1103">here</a>. For example, the following shows a rule targeting a custom chain <code class="language-plaintext highlighter-rouge">KUBE-SVC-BM6F4AVTDKG47F3K</code> for a service named <code class="language-plaintext highlighter-rouge">mysvc</code>:</p><div class="language-shell highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre><td class="rouge-code"><pre>root@kind-control-plane:/# iptables <span class="nt">-t</span> nat <span class="nt">-L</span> KUBE-SERVICES <span class="nt">-n</span> <span class="nt">-v</span>
Chain KUBE-SERVICES <span class="o">(</span>2 references<span class="o">)</span>
 pkts bytes target     prot opt <span class="k">in     </span>out     <span class="nb">source               </span>destination         
    0     0 KUBE-SVC-BM6F4AVTDKG47F3K  tcp  <span class="nt">--</span>  <span class="k">*</span>      <span class="k">*</span>       0.0.0.0/0            10.96.62.22          /<span class="k">*</span> default/mysvc cluster IP <span class="k">*</span>/ tcp dpt:8080
    0     0 KUBE-SVC-TCOU7JCQXEZGVUNU  udp  <span class="nt">--</span>  <span class="k">*</span>      <span class="k">*</span>       0.0.0.0/0            10.96.0.10           /<span class="k">*</span> kube-system/kube-dns:dns cluster IP <span class="k">*</span>/ udp dpt:53
    0     0 KUBE-SVC-ERIFXISQEP7F7OF4  tcp  <span class="nt">--</span>  <span class="k">*</span>      <span class="k">*</span>       0.0.0.0/0            10.96.0.10           /<span class="k">*</span> kube-system/kube-dns:dns-tcp cluster IP <span class="k">*</span>/ tcp dpt:53
    0     0 KUBE-SVC-JD5MR3NA4I4DYORP  tcp  <span class="nt">--</span>  <span class="k">*</span>      <span class="k">*</span>       0.0.0.0/0            10.96.0.10           /<span class="k">*</span> kube-system/kube-dns:metrics cluster IP <span class="k">*</span>/ tcp dpt:9153
    0     0 KUBE-SVC-NPX46M4PTMTKRN6Y  tcp  <span class="nt">--</span>  <span class="k">*</span>      <span class="k">*</span>       0.0.0.0/0            10.96.0.1            /<span class="k">*</span> default/kubernetes:https cluster IP <span class="k">*</span>/ tcp dpt:443
  417 25020 KUBE-NODEPORTS  all  <span class="nt">--</span>  <span class="k">*</span>      <span class="k">*</span>       0.0.0.0/0            0.0.0.0/0            /<span class="k">*</span> kubernetes service nodeports<span class="p">;</span> NOTE: this must be the last rule <span class="k">in </span>this chain <span class="k">*</span>/ ADDRTYPE match dst-type LOCAL
</pre></table></code></div></div><p>If we inspect <code class="language-plaintext highlighter-rouge">KUBE-SVC-BM6F4AVTDKG47F3K</code> we see something interesting:</p><div class="language-shell highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre>root@kind-control-plane:/# iptables <span class="nt">-t</span> nat <span class="nt">-L</span> KUBE-SVC-BM6F4AVTDKG47F3K <span class="nt">-n</span> <span class="nt">-v</span>
Chain KUBE-SVC-BM6F4AVTDKG47F3K <span class="o">(</span>1 references<span class="o">)</span>
 pkts bytes target     prot opt <span class="k">in     </span>out     <span class="nb">source               </span>destination         
    0     0 KUBE-MARK-MASQ  tcp  <span class="nt">--</span>  <span class="k">*</span>      <span class="k">*</span>      <span class="o">!</span>10.244.0.0/16        10.96.62.22          /<span class="k">*</span> default/mysvc cluster IP <span class="k">*</span>/ tcp dpt:8080
    0     0 KUBE-SEP-CMSFOBEB7HHZOTBZ  all  <span class="nt">--</span>  <span class="k">*</span>      <span class="k">*</span>       0.0.0.0/0            0.0.0.0/0            /<span class="k">*</span> default/mysvc -&gt; 10.244.1.2:8080 <span class="k">*</span>/ statistic mode random probability 0.33333333349
    0     0 KUBE-SEP-VVWLMARALSB3FCZF  all  <span class="nt">--</span>  <span class="k">*</span>      <span class="k">*</span>       0.0.0.0/0            0.0.0.0/0            /<span class="k">*</span> default/mysvc -&gt; 10.244.2.2:8080 <span class="k">*</span>/ statistic mode random probability 0.50000000000
    0     0 KUBE-SEP-XGAC3VXZG7B73WCD  all  <span class="nt">--</span>  <span class="k">*</span>      <span class="k">*</span>       0.0.0.0/0            0.0.0.0/0            /<span class="k">*</span> default/mysvc -&gt; 10.244.2.3:8080 <span class="k">*</span>/
</pre></table></code></div></div><p>Ignoring the masq for now, we see three rules targeting chains for <em>service endpoints</em>. <code class="language-plaintext highlighter-rouge">kube-proxy</code> adds these entries as it handles incoming events for endpointslices (see <a href="https://github.com/kubernetes/kubernetes/blob/b9bc0e5ac8032bb63298a407c287e6055ef073de/pkg/proxy/iptables/proxier.go#L267">NewProxier()</a>). Each rule has a helpful comment indicating the target service endpoint.</p><p>Note how these rules have a probability assigned to them. Rules in <code class="language-plaintext highlighter-rouge">iptables</code> chains are processed sequentially. In this example there are three <em>service endpoint</em> rules, and the first is assigned a probability of <code class="language-plaintext highlighter-rouge">0.33</code>. Next, if the dice roll failed on the first one, we roll it again for the second rule, this time with a probability of 50%. If that fails, we fall back to the third rule with a probability of 100%. In this way we have an even distribution of traffic amongst the three endpoints. The probabilities are set <a href="https://github.com/kubernetes/kubernetes/blob/b9bc0e5ac8032bb63298a407c287e6055ef073de/pkg/proxy/iptables/proxier.go#L1635-L1641">here</a>. Note how the probability curve is fixed as a flat distribution, and also note how <code class="language-plaintext highlighter-rouge">kube-proxy</code> is not balancing this traffic itself. As noted in <a href="#concepts">Concepts</a>, <code class="language-plaintext highlighter-rouge">kube-proxy</code> is not itself in the <em>data plane</em>.</p><p>In our example above, <code class="language-plaintext highlighter-rouge">mysvc</code> is selecting three pods with endpoints <code class="language-plaintext highlighter-rouge">10.244.1.2:8080</code>, <code class="language-plaintext highlighter-rouge">10.244.2.2:8080</code>, and <code class="language-plaintext highlighter-rouge">10.244.2.3:8080</code>.</p><p>This is the service definition:</p><div class="language-yaml highlighter-rouge"><div class="code-header"> <span data-label-text="YAML"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre><td class="rouge-code"><pre><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Service</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">labels</span><span class="pi">:</span>
    <span class="na">app</span><span class="pi">:</span> <span class="s">test</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">mysvc</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">default</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">type</span><span class="pi">:</span> <span class="s">ClusterIP</span>
  <span class="na">ports</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">port</span><span class="pi">:</span> <span class="m">8080</span>
    <span class="na">protocol</span><span class="pi">:</span> <span class="s">TCP</span>
    <span class="na">targetPort</span><span class="pi">:</span> <span class="m">8080</span>
  <span class="na">selector</span><span class="pi">:</span>
    <span class="na">app</span><span class="pi">:</span> <span class="s">test</span>
</pre></table></code></div></div><p>And these are the IPs assigned to the selected pods (take note of the nodes as well):</p><div class="language-shell highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre><span class="nv">$ </span>k get po <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span><span class="nb">test</span> <span class="nt">-o</span> wide
NAME                    READY   STATUS    RESTARTS   AGE    IP           NODE           NOMINATED NODE   READINESS GATES
test-75d6d47c7f-jcdzz   1/1     Running   0          4d7h   10.244.2.2   kind-worker2   &lt;none&gt;           &lt;none&gt;
test-75d6d47c7f-lgqcq   1/1     Running   0          4d7h   10.244.1.2   kind-worker    &lt;none&gt;           &lt;none&gt;
test-75d6d47c7f-pjrjp   1/1     Running   0          4d7h   10.244.2.3   kind-worker2   &lt;none&gt;           &lt;none&gt;
</pre></table></code></div></div><p>If we inspect one of the service endpoint chains we see something else interesting:</p><div class="language-shell highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre>root@kind-control-plane:/# iptables <span class="nt">-t</span> nat <span class="nt">-L</span> KUBE-SEP-CMSFOBEB7HHZOTBZ <span class="nt">-n</span> <span class="nt">-v</span>
Chain KUBE-SEP-CMSFOBEB7HHZOTBZ <span class="o">(</span>1 references<span class="o">)</span>
 pkts bytes target     prot opt <span class="k">in     </span>out     <span class="nb">source               </span>destination         
    0     0 KUBE-MARK-MASQ  all  <span class="nt">--</span>  <span class="k">*</span>      <span class="k">*</span>       10.244.1.2           0.0.0.0/0            /<span class="k">*</span> default/mysvc <span class="k">*</span>/
    0     0 DNAT       tcp  <span class="nt">--</span>  <span class="k">*</span>      <span class="k">*</span>       0.0.0.0/0            0.0.0.0/0            /<span class="k">*</span> default/mysvc <span class="k">*</span>/ tcp to:10.244.1.2:8080
</pre></table></code></div></div><p>We see a <code class="language-plaintext highlighter-rouge">DNAT</code> (<em>destination</em> NAT) rule that <em>translates</em> the destination address to <code class="language-plaintext highlighter-rouge">10.244.1.2:8080</code>. We already know that this destination is hosted on node <code class="language-plaintext highlighter-rouge">kind-worker</code>, so investigating on that node we see:</p><div class="language-shell highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
</pre><td class="rouge-code"><pre><span class="c"># list devices and their assigned IP ranges</span>
root@kind-worker:/# ip addr        
1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    <span class="nb">link</span>/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: veth4e573577@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default 
    <span class="nb">link</span>/ether 5a:b9:16:0d:a6:18 brd ff:ff:ff:ff:ff:ff link-netns cni-b5e04919-09af-0a9f-6945-a9929d71d789
    inet 10.244.1.1/32 scope global veth4e573577                                                             &lt;<span class="nt">------</span> 10.244.1.2 IS IN THIS RANGE
       valid_lft forever preferred_lft forever
13: eth0@if14: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default 
    <span class="nb">link</span>/ether 02:42:ac:12:00:03 brd ff:ff:ff:ff:ff:ff link-netnsid 0
    inet 172.18.0.3/16 brd 172.18.255.255 scope global eth0
       valid_lft forever preferred_lft forever
    inet6 fc00:f853:ccd:e793::3/64 scope global nodad 
       valid_lft forever preferred_lft forever
    inet6 fe80::42:acff:fe12:3/64 scope <span class="nb">link 
       </span>valid_lft forever preferred_lft forever
<span class="c"># show device</span>
root@kind-worker:/# ip <span class="nb">link </span>list veth4e573577
2: veth4e573577@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP mode DEFAULT group default 
    <span class="nb">link</span>/ether 5a:b9:16:0d:a6:18 brd ff:ff:ff:ff:ff:ff link-netns cni-b5e04919-09af-0a9f-6945-a9929d71d789   &lt;<span class="nt">------</span> NETWORK NAMESPACE
<span class="c"># list network namespaces</span>
root@kind-worker:/# ip netns list
cni-b5e04919-09af-0a9f-6945-a9929d71d789
<span class="c"># list all processes running in the target namespace</span>
root@kind-worker:/# ps <span class="si">$(</span>ip netns pids cni-b5e04919-09af-0a9f-6945-a9929d71d789<span class="si">)</span>
    PID TTY      STAT   TIME COMMAND
 505179 ?        Ss     0:00 /pause
 505237 ?        Ss     0:00 nginx: master process nginx <span class="nt">-g</span> daemon off<span class="p">;</span>
 505278 ?        S      0:00 nginx: worker process
 505279 ?        S      0:00 nginx: worker process
 505280 ?        S      0:00 nginx: worker process
 505281 ?        S      0:00 nginx: worker process
 505282 ?        S      0:00 nginx: worker process
 505283 ?        S      0:00 nginx: worker process
 505284 ?        S      0:00 nginx: worker process
 505285 ?        S      0:00 nginx: worker process
 505286 ?        S      0:00 nginx: worker process
 505287 ?        S      0:00 nginx: worker process
 505288 ?        S      0:00 nginx: worker process
 505289 ?        S      0:00 nginx: worker process
 505290 ?        S      0:00 nginx: worker process
 505291 ?        S      0:00 nginx: worker process
 505292 ?        S      0:00 nginx: worker process
 505293 ?        S      0:00 nginx: worker process
</pre></table></code></div></div><p>We are back in <code class="language-plaintext highlighter-rouge">net</code> namespace land!</p><p>In our case, we are running nginx on a simple deployment:</p><details> <summary>Spec</summary><div><div class="language-yaml highlighter-rouge"><div class="code-header"> <span data-label-text="YAML"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
</pre><td class="rouge-code"><pre><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">apps/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Deployment</span>
<span class="na">metadata</span><span class="pi">:</span>
   <span class="na">labels</span><span class="pi">:</span>
      <span class="na">app</span><span class="pi">:</span> <span class="s">test</span>
   <span class="na">name</span><span class="pi">:</span> <span class="s">test</span>
   <span class="na">namespace</span><span class="pi">:</span> <span class="s">default</span>
<span class="na">spec</span><span class="pi">:</span>
   <span class="na">replicas</span><span class="pi">:</span> <span class="m">3</span>
   <span class="na">selector</span><span class="pi">:</span>
      <span class="na">matchLabels</span><span class="pi">:</span>
         <span class="na">app</span><span class="pi">:</span> <span class="s">test</span>
   <span class="na">template</span><span class="pi">:</span>
      <span class="na">metadata</span><span class="pi">:</span>
         <span class="na">labels</span><span class="pi">:</span>
            <span class="na">app</span><span class="pi">:</span> <span class="s">test</span>
      <span class="na">spec</span><span class="pi">:</span>
         <span class="na">containers</span><span class="pi">:</span>
            <span class="pi">-</span> <span class="na">image</span><span class="pi">:</span> <span class="s">nginx</span>
              <span class="na">name</span><span class="pi">:</span> <span class="s">nginx</span>
</pre></table></code></div></div></div></details><h1 id="tying-it-all-together">Tying it all together</h1><p>Kubernetes is an event-driven, distributed platform that automates the deployment and networking aspects of your workloads. <code class="language-plaintext highlighter-rouge">kube-apiserver</code> is the platform’s “event hub”.</p><p><img data-src="/assets/img/k8s-networking/k8s-create-pod-service.svg" alt="k8s-create-pod-service" data-proofer-ignore> <em>Blue arrows show where configuration data for Deployments flow. Red arrows show where configuration data for Services flow. Note that this is just a subset of all the machinery activated when a user creates either of these two resources.</em></p><p><code class="language-plaintext highlighter-rouge">kubelet</code> runs on each node and listens for events from <code class="language-plaintext highlighter-rouge">kube-apiserver</code> where pods are added to the node it’s running on. When a pod is created, be it with a controller or just an orphaned pod, <code class="language-plaintext highlighter-rouge">kubelet</code> uses the Container Runtime Interface (CRI) to create the pod’s sandbox. The CRI in turn uses the Container Network Interface to configure the pod’s network namespace on the node. The pod will have an IP that is reachable by any other pod in any other node.</p><p>When a <code class="language-plaintext highlighter-rouge">ClusterIP</code> Service is created, <code class="language-plaintext highlighter-rouge">kube-apiserver</code> assigns a free <em>Virtual IP</em> to it and persists the Service object to <code class="language-plaintext highlighter-rouge">etcd</code>. The event is caught by <code class="language-plaintext highlighter-rouge">coreDNS</code> which proceeds to cache the service_name -&gt; cluster_ip mapping, and respond to DNS requests accordingly. The event is also caught by the EndpointSlice controller which then creates and attaches an EndpointSlice with the IPs of the selected Pods to the Service and saves the update to <code class="language-plaintext highlighter-rouge">etcd</code>.</p><p><code class="language-plaintext highlighter-rouge">kube-proxy</code> runs on each node and listens for events from <code class="language-plaintext highlighter-rouge">kube-apiserver</code> where Services and EndpointSlices are added and configures the local node’s IP routing rules to point the Service’s virtual IP to the backend Pods with an even distribution.</p><p>During runtime, a client container queries <code class="language-plaintext highlighter-rouge">coreDNS</code> for the Service’s address and directs its request to the Service’s virtual IP. The local routing rules (<code class="language-plaintext highlighter-rouge">iptables</code> on Linux hosts, <code class="language-plaintext highlighter-rouge">Host Compute Service API</code> on Windows) randomly select one of the backend Pod IP addresses and forwards traffic to that Pod.</p><p><br /> <br /></p><hr /><p><strong>Footnotes</strong></p><div class="footnotes" role="doc-endnotes"><ol><li id="fn:1" role="doc-endnote"><p>You can use the <a href="https://kubernetes.io/docs/concepts/services-networking/network-policies/">NetworkPolicy</a> resource (+ a suitable CNI plugin) to block traffic to/from Pods. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p><li id="fn:11" role="doc-endnote"><p>Despite the CNI <a href="https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/">featuring prominently in K8S docs</a>, Kubernetes does not actually interface with the CNI directly as others have pointed out <a href="https://github.com/containernetworking/cni/issues/906">here</a>. Kubernetes’ source code does not depend on the CNI API. <a href="#fnref:11" class="reversefootnote" role="doc-backlink">&#8617;</a></p><li id="fn:6" role="doc-endnote"><p>Note that <code class="language-plaintext highlighter-rouge">kube-proxy</code> is itself not actually in the request path (<em>data plane</em>). <a href="#fnref:6" class="reversefootnote" role="doc-backlink">&#8617;</a></p><li id="fn:7" role="doc-endnote"><p>Don’t worry too much: the changes done so far are not persistent across system restarts. <a href="#fnref:7" class="reversefootnote" role="doc-backlink">&#8617;</a></p><li id="fn:2" role="doc-endnote"><p>Wikipedia has a very nice description of the IP routing algorithm <a href="https://en.wikipedia.org/wiki/IP_routing#Routing_algorithm">here</a>. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a> <a href="#fnref:2:1" class="reversefootnote" role="doc-backlink">&#8617;<sup>2</sup></a></p><li id="fn:3" role="doc-endnote"><p>A reply would look like this: <code class="language-plaintext highlighter-rouge">14:47:51.365200 bridge In ifindex 5 06:82:91:69:f0:36 ethertype ARP (0x0806), length 48: Reply 10.0.0.1 is-at 06:82:91:69:f0:36, length 28</code> <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p><li id="fn:4" role="doc-endnote"><p>If you capture another dump with <code class="language-plaintext highlighter-rouge">tcpdump</code> you’ll notice an absence of <code class="language-plaintext highlighter-rouge">ARP</code> requests for <code class="language-plaintext highlighter-rouge">10.0.0.2</code>. This is because the route forwards the traffic to <code class="language-plaintext highlighter-rouge">172.18.0.4</code>, and the MAC address for the latter is already cached in the host’s ARP table. <a href="#fnref:4" class="reversefootnote" role="doc-backlink">&#8617;</a></p><li id="fn:5" role="doc-endnote"><p>In reality, Kubernetes does this in a more efficient way by configuring IP routes for IP <em>ranges</em> (segments) instead of specific addresses. You can verify IP routes on a host with <code class="language-plaintext highlighter-rouge">ip route list</code>. In my case, I could see that Kubernetes has routed <code class="language-plaintext highlighter-rouge">10.244.1.0/24</code> via <code class="language-plaintext highlighter-rouge">172.18.0.4</code> (our “server” host) and <code class="language-plaintext highlighter-rouge">10.244.2.0/24</code> via <code class="language-plaintext highlighter-rouge">172.18.0.3</code> (a third node not relevant to our discussion). <a href="#fnref:5" class="reversefootnote" role="doc-backlink">&#8617;</a></p><li id="fn:8" role="doc-endnote"><p>As described by Eli’s <a href="https://eli.thegreenplace.net/2021/plugins-in-go/">article</a> and the opposite of the <code class="language-plaintext highlighter-rouge">kubelet</code>-&gt;<code class="language-plaintext highlighter-rouge">CRI</code> integration. <code class="language-plaintext highlighter-rouge">containerd</code>’s CRI service is a plugin that is registered <a href="https://github.com/containerd/containerd/blob/b27ef6f1694aace5676306028477b12c57b84fd8/pkg/cri/cri.go#L40-L54">here</a>. <a href="#fnref:8" class="reversefootnote" role="doc-backlink">&#8617;</a></p><li id="fn:9" role="doc-endnote"><p>At the moment the CNI’s scope is limited to network-related configurations during creation and deletion of a pod. The <a href="https://github.com/containernetworking/cni#what-might-cni-do-in-the-future">README</a> notes that future extensions could be possible to enable dynamic scenarios such as <a href="https://kubernetes.io/docs/concepts/services-networking/network-policies/">NetworkPolicies</a> (<a href="https://github.com/cilium/cilium">cilium</a> already supports network policies). <a href="#fnref:9" class="reversefootnote" role="doc-backlink">&#8617;</a></p><li id="fn:10" role="doc-endnote"><p>Yet another way to implement a plugin architecture. <a href="#fnref:10" class="reversefootnote" role="doc-backlink">&#8617;</a></p><li id="fn:12" role="doc-endnote"><p>Assuming I’ve done a decent job in this article :). <a href="#fnref:12" class="reversefootnote" role="doc-backlink">&#8617;</a></p><li id="fn:13" role="doc-endnote"><p>Update is done by the <a href="https://github.com/kubernetes/kubernetes/blob/6adf60fdf4fd0428cc7f101fbbb608cd02d99cf5/pkg/controller/endpointslice/endpointslice_controller.go#L78-L170">EndpointSlice Controller</a>. We’ll talk about this and other controllers in a future article. <a href="#fnref:13" class="reversefootnote" role="doc-backlink">&#8617;</a></p><li id="fn:16" role="doc-endnote"><p>Breadcrumbs: (<a href="https://github.com/kubernetes/kubernetes/blob/12c71fdf1cf96d756ff84382adf3764af0a76d57/pkg/registry/core/service/storage/storage.go#L350">Service REST storage</a> -&gt; <a href="https://github.com/kubernetes/kubernetes/blob/1706de24d2ddc767e7cb936f60dd658880f27891/pkg/registry/core/service/storage/alloc.go#L81">allocator</a> -&gt; <a href="https://github.com/kubernetes/kubernetes/blob/ea99593fa1ef102d8a08b0884477693137ae7aec/pkg/registry/core/service/ipallocator/bitmap.go#L222">Range allocator</a> -&gt; <a href="https://github.com/kubernetes/kubernetes/blob/1b72a0f5a760649605cd833359b6dd005bb99d09/pkg/registry/core/service/allocator/storage/storage.go#L152-L176">etcd storage</a>) <a href="#fnref:16" class="reversefootnote" role="doc-backlink">&#8617;</a></p><li id="fn:17" role="doc-endnote"><p>See (<a href="https://github.com/kubernetes/apiserver/blob/27cf1d8797a919a081977c11bdcc6821de1ee341/pkg/registry/generic/registry/store.go#L436">Store.Create</a>). <a href="#fnref:17" class="reversefootnote" role="doc-backlink">&#8617;</a></p><li id="fn:14" role="doc-endnote"><p>We will cover watches in more detail in a future article. <a href="#fnref:14" class="reversefootnote" role="doc-backlink">&#8617;</a></p><li id="fn:18" role="doc-endnote"><p>Breadcrumbs: <a href="https://github.com/coredns/coredns/blob/c3228615e071de61b0c6f60d9a231c494726dda0/plugin/kubernetes/kubernetes.go#L263">InitKubeCache</a> -&gt; <a href="https://github.com/coredns/coredns/blob/c2dbb7141a7c95aa521a41b27bed3af25de8f546/plugin/kubernetes/controller.go#L409">dnsController.Run</a> -&gt; <a href="https://github.com/kubernetes/client-go/blob/2a6c116e406126324eee341e874612a5093bdbb0/tools/cache/controller.go#L153">controller.Run</a> -&gt; <a href="https://github.com/kubernetes/client-go/blob/ff6bf679aa6412abda395851a36acbea866fb724/tools/cache/reflector.go#L223">Reflector.Run</a> -&gt; <a href="https://github.com/kubernetes/client-go/blob/ff6bf679aa6412abda395851a36acbea866fb724/tools/cache/reflector.go#L329">Reflector.ListAndWatch</a> -&gt; <a href="https://github.com/kubernetes/client-go/blob/ff6bf679aa6412abda395851a36acbea866fb724/tools/cache/reflector.go#L491-L561">watchHandler</a>. <a href="#fnref:18" class="reversefootnote" role="doc-backlink">&#8617;</a></p><li id="fn:19" role="doc-endnote"><p>Breadcrumbs: <a href="https://github.com/coredns/coredns/blob/66dc74caebd4f4bdb8bd38d03b52611488424594/plugin/kubernetes/handler.go#L33">ServeDNS</a> -&gt; <a href="https://github.com/coredns/coredns/blob/c2dbb7141a7c95aa521a41b27bed3af25de8f546/plugin/backend_lookup.go#L18">A()</a> -&gt; <a href="https://github.com/coredns/coredns/blob/c2dbb7141a7c95aa521a41b27bed3af25de8f546/plugin/backend_lookup.go#L517">checkForApex</a> -&gt; <a href="https://github.com/coredns/coredns/blob/c3228615e071de61b0c6f60d9a231c494726dda0/plugin/kubernetes/kubernetes.go#L152">Services()</a> -&gt; <a href="https://github.com/coredns/coredns/blob/c3228615e071de61b0c6f60d9a231c494726dda0/plugin/kubernetes/kubernetes.go#L399">Records()</a> -&gt; <a href="https://github.com/coredns/coredns/blob/c3228615e071de61b0c6f60d9a231c494726dda0/plugin/kubernetes/kubernetes.go#L501-L594">findServices</a> -&gt; <a href="https://github.com/coredns/coredns/blob/c2dbb7141a7c95aa521a41b27bed3af25de8f546/plugin/kubernetes/controller.go#L483">SvcIndex</a> -&gt; <a href="https://github.com/kubernetes/client-go/blob/64585cf823c1b57f8c98505a2ae124a23ff83dc5/tools/cache/store.go#L217">ByIndex</a> (client-go). <a href="#fnref:19" class="reversefootnote" role="doc-backlink">&#8617;</a></p><li id="fn:20" role="doc-endnote"><p>See <a href="https://github.com/kubernetes/kubernetes/blob/6adf60fdf4fd0428cc7f101fbbb608cd02d99cf5/pkg/controller/endpointslice/endpointslice_controller.go#L307-L390">Controller.syncService</a>. <a href="#fnref:20" class="reversefootnote" role="doc-backlink">&#8617;</a></p><li id="fn:21" role="doc-endnote"><p>Breadcrumbs: <a href="https://github.com/kubernetes/kubernetes/blob/bc6c7fa91201348d010b638fbadf32007c0ac546/cmd/kube-proxy/app/server.go#L748-L752">ProxyServer.Run</a> -&gt; <a href="https://github.com/kubernetes/kubernetes/blob/2ea105df63ab0e1d0ec4d94652e32990fc06f66a/pkg/proxy/config/config.go#L169-L176">NewServiceConfig</a> -&gt; <a href="https://github.com/kubernetes/kubernetes/blob/2ea105df63ab0e1d0ec4d94652e32990fc06f66a/pkg/proxy/config/config.go#L206-L209">ServiceConfig.handleAddService</a> -&gt; <a href="https://github.com/kubernetes/kubernetes/blob/b9bc0e5ac8032bb63298a407c287e6055ef073de/pkg/proxy/iptables/proxier.go#L514-L516">Proxier.OnServiceAdd</a> -&gt; <a href="https://github.com/kubernetes/kubernetes/blob/b9bc0e5ac8032bb63298a407c287e6055ef073de/pkg/proxy/iptables/proxier.go#L522">Proxier.OnServiceUpdate</a> -&gt; <a href="https://github.com/kubernetes/kubernetes/blob/b9bc0e5ac8032bb63298a407c287e6055ef073de/pkg/proxy/iptables/proxier.go#L485">Proxier.Sync</a> -&gt; <a href="https://github.com/kubernetes/kubernetes/blob/b9bc0e5ac8032bb63298a407c287e6055ef073de/pkg/proxy/iptables/proxier.go#L789">Proxier.syncProxyRules</a>. <a href="#fnref:21" class="reversefootnote" role="doc-backlink">&#8617;</a></p><li id="fn:15" role="doc-endnote"><p><code class="language-plaintext highlighter-rouge">iptables</code> is the default. There is a newer alternative using <a href="https://en.wikipedia.org/wiki/IP_Virtual_Server">IPVS</a> that one can use by setting the <code class="language-plaintext highlighter-rouge">proxy-mode</code> appropriately (see <code class="language-plaintext highlighter-rouge">proxy-mode</code> in <a href="https://kubernetes.io/docs/reference/command-line-tools-reference/kube-proxy/#options">options</a> for <code class="language-plaintext highlighter-rouge">kube-proxy</code>). There used to be an older third mode called <em>userspace</em> but support for that was <a href="https://github.com/kubernetes/kubernetes/pull/112133">removed</a>. <a href="#fnref:15" class="reversefootnote" role="doc-backlink">&#8617;</a></p><li id="fn:22" role="doc-endnote"><p>Breadcrumbs: <a href="https://github.com/kubernetes/kubernetes/blob/b9bc0e5ac8032bb63298a407c287e6055ef073de/pkg/proxy/iptables/proxier.go#L61">kubeServicesChain</a> -&gt; <a href="https://github.com/kubernetes/kubernetes/blob/b9bc0e5ac8032bb63298a407c287e6055ef073de/pkg/proxy/iptables/proxier.go#L354-L367">iptablesJumpChains</a> -&gt; <a href="https://github.com/kubernetes/kubernetes/blob/b9bc0e5ac8032bb63298a407c287e6055ef073de/pkg/proxy/iptables/proxier.go#L857-L882">syncProxyRules</a>). <a href="#fnref:22" class="reversefootnote" role="doc-backlink">&#8617;</a></p></ol></div></div><div class="post-tail-wrapper text-muted"><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/kubernetes/" class="post-tag no-text-decoration" >kubernetes</a> <a href="/tags/k8s/" class="post-tag no-text-decoration" >k8s</a> <a href="/tags/iptables/" class="post-tag no-text-decoration" >iptables</a> <a href="/tags/networking/" class="post-tag no-text-decoration" >networking</a> <a href="/tags/kube-proxy/" class="post-tag no-text-decoration" >kube-proxy</a> <a href="/tags/kubelet/" class="post-tag no-text-decoration" >kubelet</a> <a href="/tags/containerd/" class="post-tag no-text-decoration" >containerd</a> <a href="/tags/cni/" class="post-tag no-text-decoration" >cni</a> <a href="/tags/cri/" class="post-tag no-text-decoration" >cri</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://t.me/share/url?url=https://georgearisty.dev/posts/k8s-cluster-network/&amp;text=Understanding Kubernetes&#39; Cluster Networking - George Aristy" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <a href="https://www.linkedin.com/sharing/share-offsite/?url=https://georgearisty.dev/posts/k8s-cluster-network/" data-toggle="tooltip" data-placement="top" title="Linkedin" target="_blank" rel="noopener" aria-label="Linkedin"> <i class="fa-fw fab fa-linkedin"></i> </a> <a href="https://news.ycombinator.com/submitlink?u=https://georgearisty.dev/posts/k8s-cluster-network/&amp;t=Understanding Kubernetes&#39; Cluster Networking - George Aristy" data-toggle="tooltip" data-placement="top" title="Hacker News" target="_blank" rel="noopener" aria-label="Hacker News"> <i class="fa-fw fab fa-hacker-news"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" data-title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recently Updated</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/kubectl-plugins/">Plugins I use with kubectl</a><li><a href="/posts/test-driven-development-by-example/">Test-Driven Development By Example</a><li><a href="/posts/ckad/">Certified Kubernetes Application Developer: My Experience</a><li><a href="/posts/clean-architecture/">Clean Architecture: A Craftsman's Guide to Software Structure and Design</a><li><a href="/posts/build-trap/">Escaping the Build Trap: How Effective Product Management Creates Real Value</a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/go/">go</a> <a class="post-tag" href="/tags/golang/">golang</a> <a class="post-tag" href="/tags/java/">java</a> <a class="post-tag" href="/tags/book/">book</a> <a class="post-tag" href="/tags/learning-go/">learning-go</a> <a class="post-tag" href="/tags/k8s/">k8s</a> <a class="post-tag" href="/tags/kubernetes/">kubernetes</a> <a class="post-tag" href="/tags/vim/">vim</a> <a class="post-tag" href="/tags/concurrency/">concurrency</a> <a class="post-tag" href="/tags/elegant-objects/">elegant-objects</a></div></div></div><script src="/assets/lib/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="tail-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/ckad/"><div class="card-body"> <em class="timeago small" data-ts="1652054400" > 2022-05-08 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Certified Kubernetes Application Developer: My Experience</h3><div class="text-muted small"><p> I recently passed the Certified Kubernetes Application Developer exam1 and thought I’d share my experience leading up to and during the exam. Curriculum This is the newest exam curriculum, eff...</p></div></div></a></div><div class="card"> <a href="/posts/kubernetes-in-action/"><div class="card-body"> <em class="timeago small" data-ts="1669471200" > 2022-11-26 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Kubernetes In Action</h3><div class="text-muted small"><p> Written by Marko Lukša, Kubernetes In Action is a fantastic book covering all operational aspects of Kubernetes. I find it very hard to think of a better book on the subject. This is the first edi...</p></div></div></a></div><div class="card"> <a href="/posts/kubectl-plugins/"><div class="card-body"> <em class="timeago small" data-ts="1669668000" > 2022-11-28 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Plugins I use with kubectl</h3><div class="text-muted small"><p> kubectl is the official tool to query and run changes on a Kubernetes cluster and provides a powerful and extensible CLI interface. There are many alternative tools out there that do a similar job ...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/kubectl-plugins/" class="btn btn-outline-primary" prompt="Older"><p>Plugins I use with kubectl</p></a> <a href="/posts/k8s-kube-controller-manager/" class="btn btn-outline-primary" prompt="Newer"><p>Kubernetes' Controller Manager</p></a></div><script type="text/javascript"> $(function () { const origin = "https://giscus.app"; const iframe = "iframe.giscus-frame"; const lightTheme = "light"; const darkTheme = "dark_dimmed"; let initTheme = lightTheme; if ($("html[data-mode=dark]").length > 0 || ($("html[data-mode]").length == 0 && window.matchMedia("(prefers-color-scheme: dark)").matches)) { initTheme = darkTheme; } let giscusAttributes = { "src": "https://giscus.app/client.js", "data-repo": "llorllale/llorllale.github.io", "data-repo-id": "MDEwOlJlcG9zaXRvcnk4MDM1Mjk5Ng==", "data-category": "Announcements", "data-category-id": "DIC_kwDOBMoW5M4COm92", "data-mapping": "title", "data-reactions-enabled": "1", "data-emit-metadata": "0", "data-theme": initTheme, "data-input-position": "bottom", "data-lang": "en", "crossorigin": "anonymous", "async": "" }; let giscusScript = document.createElement("script"); Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value)); document.getElementById("tail-wrapper").appendChild(giscusScript); addEventListener("message", (event) => { if (event.source === window && event.data && event.data.direction === ModeToggle.ID) { /* global theme mode changed */ const mode = event.data.message; const theme = (mode === ModeToggle.DARK_MODE ? darkTheme : lightTheme); const message = { setConfig: { theme: theme } }; const giscus = document.querySelector(iframe).contentWindow; giscus.postMessage({ giscus: message }, origin); } }); }); </script></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center text-muted"><div class="footer-left"><p class="mb-0"> © 2023 <a href="https://www.linkedin.com/in/georgearisty">George Aristy</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/go/">go</a> <a class="post-tag" href="/tags/golang/">golang</a> <a class="post-tag" href="/tags/java/">java</a> <a class="post-tag" href="/tags/book/">book</a> <a class="post-tag" href="/tags/learning-go/">learning-go</a> <a class="post-tag" href="/tags/k8s/">k8s</a> <a class="post-tag" href="/tags/kubernetes/">kubernetes</a> <a class="post-tag" href="/tags/vim/">vim</a> <a class="post-tag" href="/tags/concurrency/">concurrency</a> <a class="post-tag" href="/tags/elegant-objects/">elegant-objects</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="/assets/lib/simple-jekyll-search-1.10.0/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="/assets/lib/magnific-popup-1.1.0/jquery.magnific-popup.min.js"></script> <script src="/assets/lib/lozad-1.16.0/lozad.min.js"></script> <script src="/assets/lib/clipboard-2.0.9/clipboard.min.js"></script> <script src="/assets/lib/dayjs-1.10.7/dayjs.min.js"></script> <script src="/assets/lib/dayjs-1.10.7/locale/en.min.js"></script> <script src="/assets/lib/dayjs-1.10.7/plugin/relativeTime.min.js"></script> <script src="/assets/lib/dayjs-1.10.7/plugin/localizedFormat.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script> /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */ MathJax = { tex: { inlineMath: [ /* start/end delimiter pairs for in-line math */ ['$','$'], ['\\(','\\)'] ], displayMath: [ /* start/end delimiter pairs for display math */ ['$$', '$$'], ['\\[', '\\]'] ] } }; </script> <script src="/assets/lib/polyfill-v3-es6/polyfill.min.js"></script> <script id="MathJax-script" async src="/assets/lib/mathjax-3.2.0/tex-chtml.js"> </script> <script src="/assets/lib/bootstrap-4.6.1/bootstrap.bundle.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-P9Y4YYSCTS"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-P9Y4YYSCTS'); }); </script>
